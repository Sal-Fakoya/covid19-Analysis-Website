{
  "hash": "066642168526c86c087e08e62db70725",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Data Cleaning Process\ndate: \"2025-02-11\"\nformat: hugo-md\noutput: html_document\ntoc: true\n# jupyter: python3\n---\n\n\n\n\n# Data Cleaning Pipeline\n\nThis page outlines the data preparation process for COVID-19 analysis in the United States.\n\n## 1. Initial Setup\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n**Actions:**\n+ Clear existing environment and graphics\n+ Load essential packages:\n    - Tidyverse for data manipulation\n    - Lubridate for date handling\n    - Rio for data import\n    - Janitor for column cleaning\n+ Load custom utility functions\n\n\n\n## 2. Data Ingestion\n\n### Import Covid-19 data...\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath.origin <- \"./data/\"\ndata.dir.name.COVID19 <- list.files(path.origin) %>% str_subset(\"^csse_\")\n\ncsse_data <- tibble(directory = paste0(path.origin, data.dir.name.COVID19),\n                   file = list.files(directory)) %>%\n  mutate(path = str_c(directory, file, sep = \"/\"),\n         data = map(path, ~ read_csv(., col_types = cols(.default = \"c\")))) %>%\n  mutate(date = mdy(str_remove(file, \".csv\"))) %>%\n  select(date, data) %>%\n  unnest(data) %>%\n  clean_names()\n\n\ndf_covid19 <- csse_data\ndf_covid19 <- df_covid19 %>% \n  mutate(last_update = ymd_hms(last_update)) %>% \n  mutate_at(.tbl = .,\n            .vars = setdiff(colnames(.)[5:ncol(.)], \"iso3\"),\n            .funs = as.numeric)\n```\n:::\n\n\n\n\n**Processing Steps:**\n+ Identify CSSE COVID-19 data directory\n+ Import multiple daily reports as character data\n+ Extract dates from filenames\n+ Unnest and combine daily reports\n+ Standardize column names\n\n\n### Economic Data (GDP)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngdp_dir_name <- list.files(path.origin) %>% str_subset(\"GDP\")\n\ndf_gdp <- rio::import(file = paste0(path.origin, gdp_dir_name), sheet = \"clean data\") %>%\n  as_tibble() %>%\n  clean_names() %>%\n  select(state_or_territory, gdp_nominal = nominal_gdp_2020, \n         gdp_per_capita = gdp_per_capita_2020) %>%\n  # column conversion:\n  mutate_all(.funs = str_remove_all,\n             pattern = \",\") %>% \n  mutate_all(\n    .funs = str_remove_all,\n    pattern = \"\\\\$\") %>% \n  mutate_at(.vars = colnames(.)[2:3],\n            .funs = as.numeric)\n```\n:::\n\n\n\n\n**Key Transformations:**\n+ Remove currency symbols and commas\n+ Convert to numeric format\n+ Select relevant economic indicators\n\n### Population Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npop_dir_name <- list.files(path.origin) %>% str_subset(\"Pop\")\n\ndf_pop <- rio::import(file = paste0(path.origin, pop_dir_name), sheet = \"data\") %>%\n  as_tibble() %>%\n  clean_names() %>%\n  # column selection and cleaning\n  select(state = name, pop = pop_2019)\n```\n:::\n\n\n\n\n**Cleaning Actions:**\n+ Rename columns for consistency\n+ Select 2019 population estimates\n\n\n### Government Response Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncovid_response_dir_name <- list.files(path = path.origin) %>% str_subset(\"US_latest\")\n\ndf_covid19_response <- read_csv(file = paste0(path.origin, covid_response_dir_name),\n                               col_types = cols(.default = \"c\")) %>%\n  as_tibble() %>% \n  clean_names() %>%\n  mutate(date = ymd(date)) %>%\n  select(state = region_name, date, contains(\"index\")) %>%\n  mutate_at(.tbl = .,\n            .vars = colnames(.)[3:ncol(.)],\n            .funs = as.numeric)\n```\n:::\n\n\n\n\n**Key Features:**\n+ Parse date column\n+ Convert policy indices to numeric\n+ Standardize state column name\n\n\n### Vaccination Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvaccine_dir_name <-\n  list.files(path = path.origin) %>% \n  str_subset(\"vaccine\")\n\ndf_vaccine <- read_csv(file = paste0(path.origin,\n                                           vaccine_dir_name),\n                             col_types = cols(.default = \"c\")) %>% \n  as_tibble() %>% \n  clean_names() %>% \n  # column selection and cleaning:\n  mutate(day = ymd(day),\n         daily_vaccinations = as.numeric(daily_vaccinations)) %>% \n  select(state = entity,\n         date = day,\n         vaccinations = daily_vaccinations)\n```\n:::\n\n\n\n\n**Processing:**\n+ Convert date column\n+ Rename vaccination metric\n+ Ensure numeric vaccination counts\n\n## 3. Data Harmonization\n### State Name Standardization\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_list <- list(df_covid19, df_covid19_response, df_gdp, df_pop, df_vaccine)\ndf_list <- map(df_list, renameState)\n\n# OR use this:\ndf_covid19 <- renameState(df_covid19)\ndf_covid19_response <- renameState(df_covid19_response)\ndf_gdp <- renameState(df_gdp)\ndf_pop <- renameState(df_pop)\ndf_vaccine <- renameState(df_vaccine)\n```\n:::\n\n\n\n\n**Actions:**\n+ Apply `renameState` custom function to all datasets\n+ Ensure consistent \"state\" column name across sources\n\n\n**Datasets Overview:**\nThe analysis utilizes 5 primary datasets:\n+ df_covid19: Daily COVID-19 metrics (confirmed cases, deaths, recovered, active)\n+ df_gdp: State-level GDP data\n+ df_pop: Population estimates\n+ df_covid19_response: Government response metrics (stringency index)\n+ df_vaccine: Vaccination data\n\n\n### Missing Value Handling\nNext, we can check for missing values across all datasets:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check missing values per column in all datasets\ndf_list <- list(\n  df_covid19 = df_covid19, \n  df_gdp = df_gdp,\n  df_pop = df_pop,\n  df_covid19_response = df_covid19_response,\n  df_vaccine = df_vaccine\n)\n\nlapply(df_list, countNA)  # Custom function to count NAs\n```\n:::\n\n\n\n\n**Key findings:**\n+ Vaccination data contained 14,050 missing entries handled via imputation\n+ COVID-19 recovery/active cases showed inconsistent reporting patterns\n+ All other datasets had complete key variables\n\n### Check for Time-Span consistency of data recorded:\nWe can do this using `checkTimeSpan` custom function from previous page.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheckTimeSpan(df_covid19)  \ncheckTimeSpan(df_vaccine) \n```\n:::\n\n\n\n\n\n### State Name Standardization\nEnsured consistent state naming across datasets using fuzzy string matching:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# GET this first\nstates_list <- tibble(state_base = datasets::state.name)\n\n## do state names matching with function in funcs.R\nstates_list_covid19 <- matchStates(data = df_covid19, \n                                   col_name = \"state_covid19\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 2\n   states_base state_covid19\n   <fct>       <fct>        \n 1 Alabama     Alabama      \n 2 Alaska      Alaska       \n 3 Arizona     Arizona      \n 4 Arkansas    Arkansas     \n 5 California  California   \n 6 Colorado    Colorado     \n 7 Connecticut Connecticut  \n 8 Delaware    Delaware     \n 9 Florida     Florida      \n10 Georgia     Georgia      \n# ℹ 40 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nstates_list_gdp <- matchStates(data = df_covid19,\n                                   col_name = \"state_gdp\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 2\n   states_base state_gdp  \n   <fct>       <fct>      \n 1 Alabama     Alabama    \n 2 Alaska      Alaska     \n 3 Arizona     Arizona    \n 4 Arkansas    Arkansas   \n 5 California  California \n 6 Colorado    Colorado   \n 7 Connecticut Connecticut\n 8 Delaware    Delaware   \n 9 Florida     Florida    \n10 Georgia     Georgia    \n# ℹ 40 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nstates_list_pop <- matchStates(data = df_covid19,\n                                   col_name = \"state_pop\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 2\n   states_base state_pop  \n   <fct>       <fct>      \n 1 Alabama     Alabama    \n 2 Alaska      Alaska     \n 3 Arizona     Arizona    \n 4 Arkansas    Arkansas   \n 5 California  California \n 6 Colorado    Colorado   \n 7 Connecticut Connecticut\n 8 Delaware    Delaware   \n 9 Florida     Florida    \n10 Georgia     Georgia    \n# ℹ 40 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nstates_list_covid19_response <- matchStates(data = df_covid19,\n                                            col_name =\n                                          \"state_covid19_response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 2\n   states_base state_covid19_response\n   <fct>       <fct>                 \n 1 Alabama     Alabama               \n 2 Alaska      Alaska                \n 3 Arizona     Arizona               \n 4 Arkansas    Arkansas              \n 5 California  California            \n 6 Colorado    Colorado              \n 7 Connecticut Connecticut           \n 8 Delaware    Delaware              \n 9 Florida     Florida               \n10 Georgia     Georgia               \n# ℹ 40 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nstates_list_vaccine <- matchStates(data = df_covid19,\n                                   col_name = \"state_vaccine\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 2\n   states_base state_vaccine\n   <fct>       <fct>        \n 1 Alabama     Alabama      \n 2 Alaska      Alaska       \n 3 Arizona     Arizona      \n 4 Arkansas    Arkansas     \n 5 California  California   \n 6 Colorado    Colorado     \n 7 Connecticut Connecticut  \n 8 Delaware    Delaware     \n 9 Florida     Florida      \n10 Georgia     Georgia      \n# ℹ 40 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a universal list by joining the lists:\nstates_list <- states_list_covid19 %>% \n  inner_join(x = .,\n             y = states_list_gdp,\n             by = \"states_base\") %>% \n  inner_join(x = .,\n             y = states_list_pop,\n             by = \"states_base\") %>% \n  inner_join(x = .,\n             y = states_list_covid19_response,\n             by = \"states_base\") %>% \n  inner_join(x = .,\n             y = states_list_vaccine,\n             by = \"states_base\") %>% \n  arrange(states_base) %>% \n  mutate(state_id = row_number()) %>% \n  select(state_id, everything())\n# All states are properly matched now.\n\n# Next, add the states region\nstates_region <- tibble(states_base = state.name,\n                        region = state.region)\n\n\n## create states table: \ndf_states <- states_list %>% \n  left_join(x = .,\n            y = states_region,\n            by = \"states_base\")\n```\n:::\n\n\n\n\n**Result:**\n+ Created master state list with standardized names and IDs\n+ Removed non-state territories (e.g., Puerto Rico)\n\n### Create Main Table for Analysis by joining\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Get relevant dates:\ndf_dates <- tibble(date = seq.Date(from = df_covid19 %>% \n                                     pull(date) %>% \n                                     min(.),\n                                   to = df_covid19 %>% \n                                     pull(date) %>% max(.),\n                                   by = \"1 day\"))\n\n\n\n## Create Main table:\ndf_main <- df_states %>% \n  # cross join:\n  cross_join(x = .,\n            y = df_dates)\n\n# remove leading and trailing whitespaces in the state name for each dataframe before joining:\ndf_main <- df_main %>%\n  mutate(across(states_base:state_vaccine, str_trim))\n\ndf_covid19 <- df_covid19 %>%\n  mutate(state = str_trim(state))\n\ndf_gdp <- df_gdp %>%\n  mutate(state = str_trim(state))\n\ndf_pop <- df_pop %>%\n  mutate(state = str_trim(state))\n\ndf_covid19_response <- df_covid19_response %>%\n  mutate(state = str_trim(state))\n\ndf_vaccine <- df_vaccine %>%\n  mutate(state = str_trim(state))\n\n# then join:\ndf_joined <- df_main %>% \n  left_join(x = .,\n            y = df_covid19 %>% select(state, date, \n                                      confirmed, deaths),\n            by = c(\"state_covid19\" = \"state\",\n                   \"date\" = \"date\")) %>% \n  left_join(x = .,\n            y = df_gdp,\n            by = c(\"state_gdp\" = \"state\")) %>% \n  left_join(x = .,\n            y = df_pop,\n            by = c(\"state_pop\" = \"state\")) %>% \n  left_join(x = .,\n            y = df_vaccine,\n            by = c(\"state_vaccine\" = \"state\",\n                   \"date\" = \"date\")) %>% \n  left_join(x = .,\n            y = df_covid19_response,\n            by = c(\"state_covid19_response\" = \"state\",\n                   \"date\" = \"date\")) %>% \n  # remove redundant columns:\n  select(-c(\"state_covid19\", \"state_gdp\", \n            \"state_vaccine\", \"state_vaccine\", \"state_pop\")) %>% \n  # re-arrange:\n  select(state_id,\n         state = states_base,\n         region,\n         date,\n         confirmed_total = confirmed,\n         deaths_total = deaths,\n         daily_vacc_doses = vaccinations,\n         population = pop,\n         everything()) %>% \n  arrange(state, date)\n\n\n\ndf.main <- df_joined\n```\n:::\n\n\n\n\n**Result:**\n+ Creates a sequence of dates from minimum to maximum date sequence.\n+ Creates the main table using a cross join on the states list and the date sequence created.\n+ I removed the leading and trailing white spaces in the state names for the 5 primary datasets.\n  - I had a wrong result merging without doing this step. I found that some records were overlooked \n    and not properly match which was quite odd because I thought R automatically trims white spaces in character vectors \n    when you import the data. I'm not sure why this didn't happen for me, so I took the preventative step of removing the whitespaces myself.\n  - It is important to remove the trailing white spaces if you have wrong merging results!\n+ Merges the 5 thoroughly cleaned datasets to the `df.main` (main) table that will be used for data analysis.\n\n#### Replace Missing Values and Negative Records with Zero\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## check for missing data for non-vaccination data:\ndf.main %>% \n  filter(is.na(confirmed_total)) %>%  # to check for missing values\n  nrow()  # count the number of rows for missing values\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\ndf.main %>% \n  filter(is.na(deaths_total)) %>%  # to check for missing values\n  nrow() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\n# Get vaccination starting date:\ndf.main %>% \n  filter(is.na(daily_vacc_doses)) %>% nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14050\n```\n\n\n:::\n\n```{.r .cell-code}\n# There are 14050 missing data for vaccination doses.\n\n\n# Get the minimum date for non-missing values of vaccination doses\ndf_state_vaccDatesMin <- df.main %>% \n  filter(!is.na(daily_vacc_doses)) %>% \n  group_by(state) %>% \n  reframe(min_date = min(date)) %>% \n  summarise(min_date = min(min_date))\n\n\n## replace NAs, calculate daily counts and total counts\ndf.main <- df.main %>% \n  mutate(population_in_mil = round(population / 10e6, 2),\n         daily_vacc_doses = replace_na(daily_vacc_doses, \n                                       replace = 0)) %>%\n  # get daily count:\n  group_by(state) %>% \n  mutate(confirmed_daily_cases = \n           confirmed_total - lag(confirmed_total, n = 1),\n         death_daily_cases = \n             deaths_total - lag(deaths_total, n = 1)) %>% \n  mutate(vaccine_doses_total = cumsum(daily_vacc_doses)) %>% \n  ungroup() %>% \n  select(state_id:date,\n         confirmed_total, confirmed_daily_cases,\n         deaths_total, death_daily_cases,\n         vaccine_doses_total, daily_vacc_doses,\n         everything())\n  \n\n## check for negative values and replace them with zero, because some data were not reported:\ndf.main <- df.main %>% \n  mutate_at(.tbl = .,\n            .vars = c(\"confirmed_daily_cases\", \n                      \"death_daily_cases\", \"vaccine_doses_total\"),\n            .funs = function(.vars) {ifelse(.vars < 0, 0, .vars)}) \n\n## states to lower case:\ndf.main <- df.main %>% \n  mutate(state_ = str_to_lower(string = state))\n\nwrite.csv(x = df.main, file = \"df.main.csv\")\n```\n:::\n\n\n\n\n**Result:**\n+ Becuase I used left-join, I expect some Missing Values on the merged records. \n  - Perhaps I used have used inner join, however, I wanted to account for days where the states failed to record the cases,\n    therby, catching the inconsistencies and noting them in the EDA.\n  - Because we replaced missing records with 0, I suspected performing a lag for `confirmed_total`, `deaths_total` and `vaccine_doses_total`,\n    would cause some negative values which means there was a drop in the report from the states.\n  - I replaced these negative values with 0 since you cannot exactly say that you had negative number of reported cases. \n    This doesn't really make sense to others unless you're being mathematical.\n\n# Output Data Structure\nFinal dataset (`df.main`) contains:\n\n+ 50 states + territories\n+ Daily resolution from the minimum date\n+ Includes records across domains:\n  + Confirmed daily cases\n  + Daily Vaccination\n  + Saved as `df.main` for analysis phase.\n\n**Note:**   \n+ Policy responses and Economic indicators like the GDP will be properly looked in the EDA section\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}