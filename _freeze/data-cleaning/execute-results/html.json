{
  "hash": "03b49f4b5674dfd0b3e765a93d95f8ea",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Data Cleaning Process\ndate: \"2025-02-11\"\neditor: \n  markdown: \n    wrap: 72\nexecute: \n  warning: false\n  freeze: 'auto'\n  include: true\n---\n\n\n\n\n# Data Cleaning Pipeline\n\nThis page outlines the data preparation process for COVID-19 analysis in\nthe United States.\n\n## 1. Initial Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Environment cleanup and package loading\nrm(list = ls())\ngraphics.off()\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(cowplot)\nlibrary(rio)\nlibrary(janitor)\nlibrary(tidystringdist)\nlibrary(zoo)\n\n# after downloading the funcs.R file, uncomment the code below before running it.\nsource(\"./funcs.R\")\n```\n:::\n\n\n\n\n**Actions:**\n\n-   Clear existing environment and graphics\n\n-   Load essential packages:\n\n    -   tidyverse for data manipulation\n\n    -   lubridate for date handling\n\n    -   rio for data import\n\n    -   janitor for column cleaning\n\n-   Load custom utility functions\n\n## 2. Data Ingestion\n\n### Import Covid-19 data...\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import data using custom functions:\npath.origin <- \"./data/\" # path to data directory\n\ndata.dir.name.COVID19 <- list.files(path = path.origin) %>% \n  str_subset(\"^csse_\") # name of COVID-19 data directory\n\n\ncsse_data <- tibble(directory = paste0(path.origin, \"/\", data.dir.name.COVID19),   # main directory\n                     file = list.files(path = directory)) %>%                       # list of .csv file\n  mutate(path = str_c(directory, file, sep = \"/\")) %>%                              # create path string for import\n  mutate(data = map(.x = path,                                                      # import files with readr & map\n                    .f = function(path){read_csv(path,\n                                                  col_types = cols(.default = \"c\")) # all columns parsed as \"character\" for simplicity\n                    })) %>%   \n  mutate(date = str_remove(string = file, pattern = \".csv\"),\n         date = mdy(date)) %>% \n  select(date, data) %>% \n  unnest(cols = \"data\") %>% \n  clean_names()\n\ndf_covid19 <- csse_data\ndf_covid19 <- df_covid19 %>% \n  mutate(last_update = ymd_hms(last_update)) %>% \n  mutate_at(.tbl = .,\n            .vars = setdiff(colnames(.)[5:ncol(.)], \"iso3\"),\n            .funs = as.numeric)\n```\n:::\n\n\n\n\n**Processing Steps:**\n\n1.  Identify CSSE COVID-19 data directory\n\n2.  Import multiple daily reports as character data\n\n3.  Extract dates from filenames\n\n4.  Un-nest and combine daily reports + Standardize column names\n\n### Economic Data (GDP)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngdp_dir_name <- list.files(path = path.origin) %>% \n  str_subset(\"GDP\")\n\ndf_gdp <- rio::import(file = paste0(path.origin,\n                                    gdp_dir_name),\n                      sheet = \"clean data\") %>% \n  as_tibble() %>% \n  clean_names()\n\n# selecting columns and cleaning nominal gdp 2020 and 2019\ndf_gdp <- df_gdp %>% \n  select(state_or_territory,\n         gdp_nominal = nominal_gdp_2020,\n         gdp_per_capita = gdp_per_capita_2020) %>% \n  # column conversion:\n  mutate_all(.funs = str_remove_all,\n             pattern = \",\") %>% \n  mutate_all(\n    .funs = str_remove_all,\n    pattern = \"\\\\$\") %>% \n  mutate_at(.vars = colnames(.)[2:3],\n            .funs = as.numeric)\n```\n:::\n\n\n\n\n**Key Transformations:**\n\n-   Remove currency symbols and commas\n\n-   Convert to numeric format\n\n-   Select relevant economic indicators\n\n### Population Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npop_dir_name <- list.files(path = path.origin) %>% \n  str_subset(\"Pop\")\n\ndf_pop <- rio::import(file = paste0(path.origin,\n                                    pop_dir_name),\n                      sheet = \"data\") %>% \n  as_tibble() %>% \n  clean_names()\n\n\n## column selection and cleaning:\ndf_pop <- df_pop %>% \n  select(state = name,\n         pop = pop_2019)\n```\n:::\n\n\n\n\n**Cleaning Actions:**\n\n-   Rename columns for consistency\n\n-   Select 2019 population estimates\n\n### Government Response Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1d: Get COVID-response_data:\ncovid_response_dir_name <-\n  list.files(path = path.origin) %>% \n  str_subset(\"US_latest\")\n\ndf_covid19_response <- read_csv(file = paste0(path.origin,\n                                        covid_response_dir_name),\n                                col_types = cols(.default = \"c\")) %>% \n  as_tibble() %>% \n  clean_names()\n\n# column_selection and cleaning:\ndf_covid19_response <- df_covid19_response %>% \n  mutate(date = ymd(date)) %>% \n  select(state = region_name,\n         date,\n         contains(\"index\")) %>% \n  mutate_at(.tbl = .,\n            .vars = colnames(.)[3:ncol(.)],\n            .funs = as.numeric)\n```\n:::\n\n\n\n\n**Key Features:** + Parse date column + Convert policy indices to\nnumeric + Standardize state column name\n\n### Vaccination Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1e: Import Covid Vaccination Data:\nvaccine_dir_name <-\n  list.files(path = path.origin) %>% \n  str_subset(\"vaccine\")\n\ndf_vaccine <- read_csv(file = paste0(path.origin,\n                                           vaccine_dir_name),\n                             col_types = cols(.default = \"c\")) %>% \n  as_tibble() %>% \n  clean_names() %>% \n  # column selection and cleaning:\n  mutate(day = ymd(day),\n         daily_vaccinations = as.numeric(daily_vaccinations)) %>% \n  select(state = entity,\n         date = day,\n         vaccinations = daily_vaccinations)\n```\n:::\n\n\n\n\n**Processing:**\n\n-   Convert date column\n\n-   Rename vaccination metric + Ensure numeric vaccination counts\n\n## 3. Data Harmonization\n\n### State Name Standardization\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_covid19 <- renameState(df_covid19)\ndf_covid19_response <- renameState(df_covid19_response)\ndf_gdp <- renameState(df_gdp)\ndf_pop <- renameState(df_pop)\ndf_vaccine <- renameState(df_vaccine)\n```\n:::\n\n\n\n\n**Actions:**\n\n-   Apply `renameState` custom function to all datasets\n\n-   Ensure consistent \"state\" column name across sources\n\n**Datasets Overview:**\n\nThe analysis utilizes 5 primary datasets:\n\n-   `df_covid19:` Daily COVID-19 metrics (confirmed cases, deaths,\n    recovered, active)\n\n-   `df_gdp`: State-level GDP data\n\n-   `df_pop`: Population estimates\n\n-   `df_covid19_response`: Government response metrics (stringency\n    index)\n\n-   `df_vaccine`: Vaccination data\n\n## Export Cleaned Data\n\nAt the time of documenting, I exported the unmerged data, if you would\nlike to perform some analysis on your own with it. You should be able to\nsee it in my github repo as \\`df.main.csv\\` file.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndir = \"./exported-data\"\n\nif (!dir.exists(dir))\n{\n  dir.create(dir)\n}\n\ndf_covid19 <- write.csv(x = df_covid19, file = paste0(dir, \"/\", \"df-covid19.csv\"))\ndf_covid19_response <- write.csv(x = df_covid19_response, file=paste0(dir, \"/\", \"df-covid19-response.csv\"))\ndf_gdp <- write.csv(x = df_gdp, file = paste0(dir, \"/\", \"df-gdp.csv\"))\ndf_pop <- write.csv(x = df_pop, file = paste0(dir, \"/\", \"df-pop.csv\"))\ndf_vaccine <- write.csv(x = df_vaccine, file = paste0(dir, \"/\", \"df-vaccine.csv\"))\n```\n:::\n",
    "supporting": [
      "data-cleaning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}