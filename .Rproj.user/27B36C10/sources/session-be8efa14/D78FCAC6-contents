[
  {
    "objectID": "funcs.html",
    "href": "funcs.html",
    "title": "Custom Functions",
    "section": "",
    "text": "This page explains the purpose and usage of custom functions developed for the COVID-19 exploratory data analysis performed in this project."
  },
  {
    "objectID": "funcs.html#data-preparation-functions",
    "href": "funcs.html#data-preparation-functions",
    "title": "Custom Functions",
    "section": "1. Data Preparation Functions",
    "text": "1. Data Preparation Functions\n\nrenameState(df)\nPurpose: Standardizes state column naming across datasets\nParameters: df: Input dataframe\nDescription:\nRenames any column containing “state” in its name to “state”. Ensures consistent column naming across different datasets.\n\n\nCode\nrenameState &lt;- function(df) {\n  df %&gt;% rename_with(~ \"state\", contains(\"state\"))\n}\n\n\n\n\nmatchStates(states_base=states_list, data, col_name)\nPurpose:\n\nAlso for data wrangling purpose, it fuzzy matches the U.S state names to a states_base column as reference.\nThe states_base used in my EDA is from the datasets::state.name.\n\nParameters:\n\nstates_base: Reference list of states (default: states_list in the datasets::state.name)\ndata: Dataset containing state names to match - col_name Name of column containing state names in the data parameter.\n\nDescription:\nUses Optimal String Alignment (OSA) distance to match state names between datasets and reference list. Helps resolve naming inconsistencies.\n\n\nCode\nmatchStates &lt;- function(states_base = states_list,\n                        data,\n                        col_name)\n{\n  require(tidystringdist)\n  require(rlang)\n  \n  # extract unique state names from given data source.\n  states_data &lt;- data %&gt;% \n    distinct(state)\n  \n  # create table of all combinations: state pairs:\n  states_comb &lt;- expand.grid(states_base = states_list %&gt;% \n                               pull(state_base),\n                             state = states_data %&gt;% pull(state))\n  \n  # compute string distance:\n  t1 &lt;- tidy_stringdist(df = states_comb,\n                  v1 = states_base,\n                  v2 = state,\n                  method = \"osa\") %&gt;% \n    # sort best name match per state and add matching rank:\n    arrange(states_base, osa) %&gt;% \n    group_by(states_base) %&gt;% \n    mutate(rank = row_number()) %&gt;% \n    ungroup() %&gt;% \n    # filter top ranks:\n    filter(rank == 1) %&gt;% \n    select(states_base, {{ col_name }} := state)\n  \n  print(t1)\n  \n  \n  # t2 is an easier fix...\n  t2 &lt;- tidy_stringdist(df = states_comb,\n                        v1 = states_base,\n                        v2 = state,\n                        method = \"osa\") %&gt;% \n    filter(osa == 0) %&gt;% \n    select(states_base, state) %&gt;% \n    arrange(states_base)\n  \n  return (t1)\n  \n}"
  },
  {
    "objectID": "funcs.html#data-inspection-functions",
    "href": "funcs.html#data-inspection-functions",
    "title": "Custom Functions",
    "section": "2. Data Inspection Functions",
    "text": "2. Data Inspection Functions\n\ncountNA(df)\nPurpose: Analyzes missing values patterns\nParameters: df: Input dataframe\nOutputs:\n\nDataframe with NA counts and percentages\nDual plots (absolute counts and percentages)\n\nDescription:\nProvides missing value analysis with numerical summary and visual representation.\n\n\nCode\ncountNA &lt;- function(df) {\n  require(tidyverse)\n  require(cowplot)\n  \n  # Count NAs using summarise across all columns\n  df_na_count &lt;- df %&gt;%\n    summarise(across(everything(), ~ sum(is.na(.)))) %&gt;%\n    pivot_longer(cols = everything(), names_to = \"col\", values_to = \"NAs\") %&gt;%\n    mutate(NA_perc = round(NAs / nrow(df) * 100, 2))\n  \n  print(df_na_count)\n  \n  # Absolute NA count plot\n  p1 &lt;- df_na_count %&gt;%\n    ggplot(aes(x = col, y = NAs, fill = col)) +\n    geom_col(show.legend = FALSE) +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 90, face = \"bold\")) +\n    scale_fill_viridis_d(option = \"magma\") +\n    scale_x_discrete(labels = function(x) str_trunc(x, width = 10, ellipsis = \"...\")) +\n    geom_text(aes(label = NAs), vjust = 0)\n  \n  # Relative NA percentage plot\n  p2 &lt;- df_na_count %&gt;%\n    ggplot(aes(x = col, y = NA_perc, fill = col)) +\n    geom_col(show.legend = FALSE) +\n    scale_y_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 90, face = \"bold\")) +\n    scale_fill_viridis_d(option = \"magma\") +\n    scale_x_discrete(labels = function(x) str_trunc(x, width = 12, ellipsis = \"...\")) +\n    geom_text(aes(label = paste0(NA_perc, \"%\")), vjust = 0)\n  \n  plot_grid(p1, p2, nrow = 2)\n}\n\n\n\n\ncheckTimeSpan(df)\nPurpose:\nChecks distinct dates for each state and returns a bar plot showing the maximum and minimum date, thereby allowing us to check states with useful data.\nParameters:\n\ndf: Input dataframe with date column\n\nOutputs:\n\nDate range on a bar plot\n\nDescription:\n\nreturns a barplot showing the states with their maximum and minimum dates. There is no conclusion to be made based on these plots, however, I found Puerto Rico and United States as part of the states on this plot. This will be filtered out later in the data cleaning process."
  },
  {
    "objectID": "funcs.html#visualization-functions",
    "href": "funcs.html#visualization-functions",
    "title": "Custom Functions",
    "section": "3. Visualization Functions",
    "text": "3. Visualization Functions\n\nplotConfirmedCasesTotal(data=df.main, region.group)\nPurpose: Tracks pandemic progression based on region.\nParameters:\n\ndata: Main dataframe (default: df.main)\nregion.group: Geographic region to analyze\n\nOutput:\n\n2x2 panel plot with absolute/relative infection cases and deaths over time on a state level.\nAuto-saves PNG to ./explore directory and creates the ./explore directory if it does not exist.\n\nDescription:\nShows both absolute counts and population-adjusted percentages for COVID-19 metrics across states for each region.group\n\n\nCode\nplotConfirmedCasesTotal &lt;- function(data = df.main, region.group)\n{\n  \n  # data:\n  plot_data &lt;- data %&gt;% \n    filter(region_group == region.group)\n  \n  # confirmed cases absolute count\n  p11 &lt;- plot_data %&gt;% \n    ggplot(mapping = aes(x = date,\n                         y = confirmed_total,\n                         group = state,\n                         color = state)) +\n    geom_line() +\n    geom_point(alpha = 0.7) +\n    scale_colour_viridis_d() +\n    xlab(\"Date\") +\n    ylab(\"Number of Confirmed cases total\") +\n    ggtitle(paste(\"Infected Cases /\", region.group, sep = \" \")) +\n    theme_minimal()\n  \n  print(p11)\n  \n  ## confirmed cases relative count:\n  p21 &lt;- plot_data %&gt;% \n    ggplot(mapping = aes(x = date,\n                         y = confirmed_totalPerc,\n                         group = state,\n                         color = state)) +\n    geom_line() +\n    geom_point(alpha = 0.7) +\n    scale_colour_viridis_d() +\n    xlab(\"Date\") +\n    ylab(\"Percentage(%) of Confirmed cases total\") +\n    ggtitle(paste(\"Infected Cases /\", region.group, sep = \" \")) +\n    theme_minimal()\n  \n  print(p21)\n  \n  \n  # death cases absolute count\n  p12 &lt;- plot_data %&gt;% \n    ggplot(mapping = aes(x = date,\n                         y = deaths_total,\n                         group = state,\n                         color = state)) +\n    geom_line() +\n    geom_point(alpha = 0.7) +\n    scale_colour_viridis_d() +\n    xlab(\"Date\") +\n    ylab(\"Number of Deaths total\") +\n    ggtitle(paste(\"Death /\", region.group, sep = \" \")) +\n    theme_minimal()\n  \n  print(p12)\n  \n  ## confirmed cases relative count:\n  p22 &lt;- plot_data %&gt;% \n    ggplot(mapping = aes(x = date,\n                         y = deaths_totalPerc,\n                         group = state,\n                         color = state)) +\n    geom_line() +\n    geom_point(alpha = 0.7) +\n    scale_colour_viridis_d() +\n    xlab(\"Date\") +\n    ylab(\"Percentage(%) of Deaths total\") +\n    ggtitle(paste(\"Death /\", region.group, sep = \" \")) +\n    theme_minimal()\n  \n  print(p22)\n  \n  plot &lt;- plot_grid(p11, p12, p21, p22, nrow = 2, ncol = 2)\n  \n  #plot_export\n  \n  if (!dir.exists(\"./explore\"))\n  {\n    dir.create(\"./explore\")\n  }\n  \n  ggsave(filename = paste(\"./explore/01_confirmed_cases_and_deaths\",\n                          region.group, \".png\"),\n         plot = plot,\n         width = 30, height = 20, \n         units = \"cm\",\n         dpi = 1200)\n  \n}\n\n\n\n\nplot7DayAverage(data=df.main, region.group, output_dir=\"./explore\")\nPurpose: Analyzes trend of Covid-19 infection cases and death trend on a 7 day average for each region.\nParameters:\n\ndata: Main dataframe (default: df.main)\nregion.group: Geographic region\n\n\n\noutput_dir: directory to save plot (default: ./explore)\n\nFeatures:\n\nError checking for valid region groups\nModular plot generation\nStandardized plot-saving format\n\nOutput:\nDual time series plots of 7-day moving averages for infection cases and deaths.\n\n\nCode\nplot7DayAverage &lt;- function(data = df.main, region.group, output_dir = \"./explore\") \n  {\n  # Ensure necessary libraries are loaded\n  require(ggplot2)\n  require(cowplot)\n  require(viridis)\n  require(rlang)\n  \n  # Verify that region.group exists\n  if (!region.group %in% unique(data$region_group)) {\n    stop(\"Error: The specified region.group does not exist in the data.\")\n  }\n  \n  # Filter data\n  plot_data &lt;- data %&gt;% \n    filter(region_group == region.group)\n  \n  # Helper function for creating plots\n  create_plot &lt;- function(data = plot.data, \n                          y_var, title_text, y_label_text) {\n    data %&gt;%\n      ggplot(aes(x = date, y = {{ y_var }}, group = state, color = state)) +\n      geom_line(alpha = 0.8, linewidth = 0.8) +\n      geom_point(alpha = 0.8, size = 0.8, show.legend = FALSE) +\n      scale_colour_viridis_d() +\n      labs(title = paste(title_text, \"-\", region.group),\n           x = \"Date\",\n           y = y_label_text,\n           color = \"State\") +\n      theme_minimal() +\n      theme(plot.title = element_text(hjust = 0.5))\n  }\n  \n  # Create plots\n  p1 &lt;- create_plot(plot_data, \n                    `confirmed_daily_cases 7d Avg`, \n                    \"Infected Daily Cases\", \n                    \"7-Day Moving Average of Confirmed Cases\")\n  p2 &lt;- create_plot(plot_data, \n                    `death_daily_cases 7d Avg`, \n                    \"Deaths\", \n                    \"7-Day Moving Average of Deaths\")\n  \n  # Combine plots\n  combined_plot &lt;- plot_grid(p1, p2, nrow = 2)\n  \n  # Create output directory if it doesn't exist\n  if (!dir.exists(output_dir)) {\n    dir.create(output_dir)\n  }\n  \n  # Construct filename\n  filename &lt;- file.path(output_dir, paste0(\"03_confirmed_cases_and_deaths_on_7Day_Avg_\", region.group, \".png\"))\n  \n  # Save plot\n  ggsave(filename = filename,\n         plot = combined_plot,\n         width = 35, height = 25, units = \"cm\",\n         dpi = 1200)\n  \n  # Return the combined plot\n  return(combined_plot)\n}\n\n\n\n\nplotCovid19Map_overTime(data=df.main, var, output_dir=\"./explore\")\nPurpose: Show on map how number of COVID-case have changed over time (monthly)\nParameters:\n\ndata: Main dataframe\nvar: Variable to visualize (confirmed_total/deaths_total/vaccine_doses_total)\noutput_dir: Save location for plots to ./explore directory by default and creates the directory if it does not exist.\n\nOutput:\nFaceted chloropleth map showing variable var evolution across monthly snapshots.\n\n\nCode\nplotCovid19Map_overTime &lt;- function(data = df.main, var,\n                                    output_dir = \"./explore\") \n  {\n  \n  # Ensure the necessary libraries are loaded\n  require(ggplot2)\n  require(cowplot)\n  require(viridis)\n  require(rlang)\n  \n  # Filter and prepare data\n  plot_data &lt;- data %&gt;% \n    filter(date_snapshot_flag) %&gt;% \n    select(region, state_, state, date, confirmed_total, deaths_total, vaccine_doses_total, stringency_index_for_display) %&gt;% \n    left_join(map_data(\"state\"), by = c(\"state_\" = \"region\"))\n  \n  # Helper function for creating plots\n  create_plot &lt;- function(data, var, title_text) {\n    data %&gt;%\n      ggplot(aes(x = long, y = lat, group = group)) +\n      geom_polygon(aes_string(fill = var), \n                   color = \"black\", show.legend = TRUE) +\n      facet_wrap(~ date) +\n      ggtitle(title_text) +\n      theme_bw() + \n      theme(axis.ticks = element_blank(),\n            axis.text = element_blank(),\n            plot.title = element_text(hjust = 0.5)) + \n      scale_fill_gradient(low = \"white\", high = \"red\")\n  }\n  \n  # Create plot based on variable\n  title &lt;- paste(\"Map of Covid-19\", gsub(\"_\", \" \", var), \"Over Time\")\n  plot &lt;- create_plot(plot_data, var, title)\n  \n  # Create output directory if it doesn't exist\n  if (!dir.exists(output_dir)) {\n    dir.create(output_dir)\n  }\n  \n  # Construct filename\n  filename &lt;- file.path(output_dir, paste0(\"06_Map_of_\", var, \"_over_time.png\"))\n  \n  # Save plot\n  ggsave(filename = filename, plot = plot, width = 35,\n         height = 25, units = \"cm\", dpi = 1200)\n  \n  # Return the plot\n  return(plot)\n}"
  },
  {
    "objectID": "funcs.html#advanced-analysis-function",
    "href": "funcs.html#advanced-analysis-function",
    "title": "Custom Functions",
    "section": "4 Advanced Analysis Function:",
    "text": "4 Advanced Analysis Function:\n\nplotCovid19Indicators_stateLevel(data=df.main, state_selection, output_dir=\"./explore\")\n\n\nCode\nplotCovid19Map_overTime &lt;- function(data = df.main, var,\n                                    output_dir = \"./explore\") \n  {\n  \n  # Ensure the necessary libraries are loaded\n  require(ggplot2)\n  require(cowplot)\n  require(viridis)\n  require(rlang)\n  \n  # Filter and prepare data\n  plot_data &lt;- data %&gt;% \n    filter(date_snapshot_flag) %&gt;% \n    select(region, state_, state, date, confirmed_total, deaths_total, vaccine_doses_total, stringency_index_for_display) %&gt;% \n    left_join(map_data(\"state\"), by = c(\"state_\" = \"region\"))\n  \n  # Helper function for creating plots\n  create_plot &lt;- function(data, var, title_text) {\n    data %&gt;%\n      ggplot(aes(x = long, y = lat, group = group)) +\n      geom_polygon(aes_string(fill = var), \n                   color = \"black\", show.legend = TRUE) +\n      facet_wrap(~ date) +\n      ggtitle(title_text) +\n      theme_bw() + \n      theme(axis.ticks = element_blank(),\n            axis.text = element_blank(),\n            plot.title = element_text(hjust = 0.5)) + \n      scale_fill_gradient(low = \"white\", high = \"red\")\n  }\n  \n  # Create plot based on variable\n  title &lt;- paste(\"Map of Covid-19\", gsub(\"_\", \" \", var), \"Over Time\")\n  plot &lt;- create_plot(plot_data, var, title)\n  \n  # Create output directory if it doesn't exist\n  if (!dir.exists(output_dir)) {\n    dir.create(output_dir)\n  }\n  \n  # Construct filename\n  filename &lt;- file.path(output_dir, paste0(\"06_Map_of_\", var, \"_over_time.png\"))\n  \n  # Save plot\n  ggsave(filename = filename, plot = plot, width = 35,\n         height = 25, units = \"cm\", dpi = 1200)\n  \n  # Return the plot\n  return(plot)\n}\n\n\nPurpose:\nPlots Covid-19 Indicators (infection, deaths and government response) at the state-level monthly (there is a date snapshot flag for every 30th day captured in the in the EDA section before this function is called).\nParameters:\n\ndata: Main dataframe (default: df.main)\nstate_selection: Target state\noutput_dir: Saves plot to location (\"./explore\" by default) and creates the directory if it does not exist.\n\nOutputs:\n\nStacked area chart: Cumulative totals\nLog-scale time series: 7-day averages\nGovernment response metrics\n\nDescription: Plots and saves the stacked area chart in the output_dir."
  },
  {
    "objectID": "data-cleaning.html",
    "href": "data-cleaning.html",
    "title": "Data Cleaning Process",
    "section": "",
    "text": "This page outlines the data preparation process for COVID-19 analysis in the United States.\n\n\nActions:\n\nClear existing environment and graphics\nLoad essential packages:\n\ntidyverse for data manipulation\nlubridate for date handling\nrio for data import\njanitor for column cleaning\n\nLoad custom utility functions\n\n\n\n\n\n\n\n\nCode\n# import data using custom functions:\npath.origin &lt;- \"./data/\" # path to data directory\n\ndata.dir.name.COVID19 &lt;- list.files(path = path.origin) %&gt;% \n  str_subset(\"^csse_\") # name of COVID-19 data directory\n\n\ncsse_data &lt;- tibble(directory = paste0(path.origin, \"/\", data.dir.name.COVID19),   # main directory\n                     file = list.files(path = directory)) %&gt;%                       # list of .csv file\n  mutate(path = str_c(directory, file, sep = \"/\")) %&gt;%                              # create path string for import\n  mutate(data = map(.x = path,                                                      # import files with readr & map\n                    .f = function(path){read_csv(path,\n                                                  col_types = cols(.default = \"c\")) # all columns parsed as \"character\" for simplicity\n                    })) %&gt;%   \n  mutate(date = str_remove(string = file, pattern = \".csv\"),\n         date = mdy(date)) %&gt;% \n  select(date, data) %&gt;% \n  unnest(cols = \"data\") %&gt;% \n  clean_names()\n\ndf_covid19 &lt;- csse_data\ndf_covid19 &lt;- df_covid19 %&gt;% \n  mutate(last_update = ymd_hms(last_update)) %&gt;% \n  mutate_at(.tbl = .,\n            .vars = setdiff(colnames(.)[5:ncol(.)], \"iso3\"),\n            .funs = as.numeric)\n\n\nProcessing Steps:\n\nIdentify CSSE COVID-19 data directory\nImport multiple daily reports as character data\nExtract dates from filenames\nUn-nest and combine daily reports + Standardize column names\n\n\n\n\n\n\nCode\ngdp_dir_name &lt;- list.files(path = path.origin) %&gt;% \n  str_subset(\"GDP\")\n\ndf_gdp &lt;- rio::import(file = paste0(path.origin,\n                                    gdp_dir_name),\n                      sheet = \"clean data\") %&gt;% \n  as_tibble() %&gt;% \n  clean_names()\n\n# selecting columns and cleaning nominal gdp 2020 and 2019\ndf_gdp &lt;- df_gdp %&gt;% \n  select(state_or_territory,\n         gdp_nominal = nominal_gdp_2020,\n         gdp_per_capita = gdp_per_capita_2020) %&gt;% \n  # column conversion:\n  mutate_all(.funs = str_remove_all,\n             pattern = \",\") %&gt;% \n  mutate_all(\n    .funs = str_remove_all,\n    pattern = \"\\\\$\") %&gt;% \n  mutate_at(.vars = colnames(.)[2:3],\n            .funs = as.numeric)\n\n\nKey Transformations:\n\nRemove currency symbols and commas\nConvert to numeric format\nSelect relevant economic indicators\n\n\n\n\n\n\nCode\npop_dir_name &lt;- list.files(path = path.origin) %&gt;% \n  str_subset(\"Pop\")\n\ndf_pop &lt;- rio::import(file = paste0(path.origin,\n                                    pop_dir_name),\n                      sheet = \"data\") %&gt;% \n  as_tibble() %&gt;% \n  clean_names()\n\n\n## column selection and cleaning:\ndf_pop &lt;- df_pop %&gt;% \n  select(state = name,\n         pop = pop_2019)\n\n\nCleaning Actions:\n\nRename columns for consistency\nSelect 2019 population estimates\n\n\n\n\n\n\nCode\n# Step 1d: Get COVID-response_data:\ncovid_response_dir_name &lt;-\n  list.files(path = path.origin) %&gt;% \n  str_subset(\"US_latest\")\n\ndf_covid19_response &lt;- read_csv(file = paste0(path.origin,\n                                        covid_response_dir_name),\n                                col_types = cols(.default = \"c\")) %&gt;% \n  as_tibble() %&gt;% \n  clean_names()\n\n# column_selection and cleaning:\ndf_covid19_response &lt;- df_covid19_response %&gt;% \n  mutate(date = ymd(date)) %&gt;% \n  select(state = region_name,\n         date,\n         contains(\"index\")) %&gt;% \n  mutate_at(.tbl = .,\n            .vars = colnames(.)[3:ncol(.)],\n            .funs = as.numeric)\n\n\nKey Features: + Parse date column + Convert policy indices to numeric + Standardize state column name\n\n\n\n\n\nCode\n# Step 1e: Import Covid Vaccination Data:\nvaccine_dir_name &lt;-\n  list.files(path = path.origin) %&gt;% \n  str_subset(\"vaccine\")\n\ndf_vaccine &lt;- read_csv(file = paste0(path.origin,\n                                           vaccine_dir_name),\n                             col_types = cols(.default = \"c\")) %&gt;% \n  as_tibble() %&gt;% \n  clean_names() %&gt;% \n  # column selection and cleaning:\n  mutate(day = ymd(day),\n         daily_vaccinations = as.numeric(daily_vaccinations)) %&gt;% \n  select(state = entity,\n         date = day,\n         vaccinations = daily_vaccinations)\n\n\nProcessing:\n\nConvert date column\nRename vaccination metric + Ensure numeric vaccination counts\n\n\n\n\n\n\n\n\n\nCode\ndf_covid19 &lt;- renameState(df_covid19)\ndf_covid19_response &lt;- renameState(df_covid19_response)\ndf_gdp &lt;- renameState(df_gdp)\ndf_pop &lt;- renameState(df_pop)\ndf_vaccine &lt;- renameState(df_vaccine)\n\n\nActions:\n\nApply renameState custom function to all datasets\nEnsure consistent “state” column name across sources\n\nDatasets Overview:\nThe analysis utilizes 5 primary datasets:\n\ndf_covid19: Daily COVID-19 metrics (confirmed cases, deaths, recovered, active)\ndf_gdp: State-level GDP data\ndf_pop: Population estimates\ndf_covid19_response: Government response metrics (stringency index)\ndf_vaccine: Vaccination data\n\n\n\n\n\nAt the time of documenting, I exported the unmerged data, if you would like to perform some analysis on your own with it. You should be able to see it in my github repo as `df.main.csv` file.\n\n\nCode\ndir = \"./exported-data\"\n\nif (!dir.exists(dir))\n{\n  dir.create(dir)\n}\n\ndf_covid19 &lt;- write.csv(x = df_covid19, file = paste0(dir, \"/\", \"df-covid19.csv\"))\ndf_covid19_response &lt;- write.csv(x = df_covid19_response, file=paste0(dir, \"/\", \"df-covid19-response.csv\"))\ndf_gdp &lt;- write.csv(x = df_gdp, file = paste0(dir, \"/\", \"df-gdp.csv\"))\ndf_pop &lt;- write.csv(x = df_pop, file = paste0(dir, \"/\", \"df-pop.csv\"))\ndf_vaccine &lt;- write.csv(x = df_vaccine, file = paste0(dir, \"/\", \"df-vaccine.csv\"))"
  },
  {
    "objectID": "data-cleaning.html#initial-setup",
    "href": "data-cleaning.html#initial-setup",
    "title": "Data Cleaning Process",
    "section": "",
    "text": "Actions:\n\nClear existing environment and graphics\nLoad essential packages:\n\ntidyverse for data manipulation\nlubridate for date handling\nrio for data import\njanitor for column cleaning\n\nLoad custom utility functions"
  },
  {
    "objectID": "data-cleaning.html#data-ingestion",
    "href": "data-cleaning.html#data-ingestion",
    "title": "Data Cleaning Process",
    "section": "",
    "text": "Code\n# import data using custom functions:\npath.origin &lt;- \"./data/\" # path to data directory\n\ndata.dir.name.COVID19 &lt;- list.files(path = path.origin) %&gt;% \n  str_subset(\"^csse_\") # name of COVID-19 data directory\n\n\ncsse_data &lt;- tibble(directory = paste0(path.origin, \"/\", data.dir.name.COVID19),   # main directory\n                     file = list.files(path = directory)) %&gt;%                       # list of .csv file\n  mutate(path = str_c(directory, file, sep = \"/\")) %&gt;%                              # create path string for import\n  mutate(data = map(.x = path,                                                      # import files with readr & map\n                    .f = function(path){read_csv(path,\n                                                  col_types = cols(.default = \"c\")) # all columns parsed as \"character\" for simplicity\n                    })) %&gt;%   \n  mutate(date = str_remove(string = file, pattern = \".csv\"),\n         date = mdy(date)) %&gt;% \n  select(date, data) %&gt;% \n  unnest(cols = \"data\") %&gt;% \n  clean_names()\n\ndf_covid19 &lt;- csse_data\ndf_covid19 &lt;- df_covid19 %&gt;% \n  mutate(last_update = ymd_hms(last_update)) %&gt;% \n  mutate_at(.tbl = .,\n            .vars = setdiff(colnames(.)[5:ncol(.)], \"iso3\"),\n            .funs = as.numeric)\n\n\nProcessing Steps:\n\nIdentify CSSE COVID-19 data directory\nImport multiple daily reports as character data\nExtract dates from filenames\nUn-nest and combine daily reports + Standardize column names\n\n\n\n\n\n\nCode\ngdp_dir_name &lt;- list.files(path = path.origin) %&gt;% \n  str_subset(\"GDP\")\n\ndf_gdp &lt;- rio::import(file = paste0(path.origin,\n                                    gdp_dir_name),\n                      sheet = \"clean data\") %&gt;% \n  as_tibble() %&gt;% \n  clean_names()\n\n# selecting columns and cleaning nominal gdp 2020 and 2019\ndf_gdp &lt;- df_gdp %&gt;% \n  select(state_or_territory,\n         gdp_nominal = nominal_gdp_2020,\n         gdp_per_capita = gdp_per_capita_2020) %&gt;% \n  # column conversion:\n  mutate_all(.funs = str_remove_all,\n             pattern = \",\") %&gt;% \n  mutate_all(\n    .funs = str_remove_all,\n    pattern = \"\\\\$\") %&gt;% \n  mutate_at(.vars = colnames(.)[2:3],\n            .funs = as.numeric)\n\n\nKey Transformations:\n\nRemove currency symbols and commas\nConvert to numeric format\nSelect relevant economic indicators\n\n\n\n\n\n\nCode\npop_dir_name &lt;- list.files(path = path.origin) %&gt;% \n  str_subset(\"Pop\")\n\ndf_pop &lt;- rio::import(file = paste0(path.origin,\n                                    pop_dir_name),\n                      sheet = \"data\") %&gt;% \n  as_tibble() %&gt;% \n  clean_names()\n\n\n## column selection and cleaning:\ndf_pop &lt;- df_pop %&gt;% \n  select(state = name,\n         pop = pop_2019)\n\n\nCleaning Actions:\n\nRename columns for consistency\nSelect 2019 population estimates\n\n\n\n\n\n\nCode\n# Step 1d: Get COVID-response_data:\ncovid_response_dir_name &lt;-\n  list.files(path = path.origin) %&gt;% \n  str_subset(\"US_latest\")\n\ndf_covid19_response &lt;- read_csv(file = paste0(path.origin,\n                                        covid_response_dir_name),\n                                col_types = cols(.default = \"c\")) %&gt;% \n  as_tibble() %&gt;% \n  clean_names()\n\n# column_selection and cleaning:\ndf_covid19_response &lt;- df_covid19_response %&gt;% \n  mutate(date = ymd(date)) %&gt;% \n  select(state = region_name,\n         date,\n         contains(\"index\")) %&gt;% \n  mutate_at(.tbl = .,\n            .vars = colnames(.)[3:ncol(.)],\n            .funs = as.numeric)\n\n\nKey Features: + Parse date column + Convert policy indices to numeric + Standardize state column name\n\n\n\n\n\nCode\n# Step 1e: Import Covid Vaccination Data:\nvaccine_dir_name &lt;-\n  list.files(path = path.origin) %&gt;% \n  str_subset(\"vaccine\")\n\ndf_vaccine &lt;- read_csv(file = paste0(path.origin,\n                                           vaccine_dir_name),\n                             col_types = cols(.default = \"c\")) %&gt;% \n  as_tibble() %&gt;% \n  clean_names() %&gt;% \n  # column selection and cleaning:\n  mutate(day = ymd(day),\n         daily_vaccinations = as.numeric(daily_vaccinations)) %&gt;% \n  select(state = entity,\n         date = day,\n         vaccinations = daily_vaccinations)\n\n\nProcessing:\n\nConvert date column\nRename vaccination metric + Ensure numeric vaccination counts"
  },
  {
    "objectID": "data-cleaning.html#data-harmonization",
    "href": "data-cleaning.html#data-harmonization",
    "title": "Data Cleaning Process",
    "section": "",
    "text": "Code\ndf_covid19 &lt;- renameState(df_covid19)\ndf_covid19_response &lt;- renameState(df_covid19_response)\ndf_gdp &lt;- renameState(df_gdp)\ndf_pop &lt;- renameState(df_pop)\ndf_vaccine &lt;- renameState(df_vaccine)\n\n\nActions:\n\nApply renameState custom function to all datasets\nEnsure consistent “state” column name across sources\n\nDatasets Overview:\nThe analysis utilizes 5 primary datasets:\n\ndf_covid19: Daily COVID-19 metrics (confirmed cases, deaths, recovered, active)\ndf_gdp: State-level GDP data\ndf_pop: Population estimates\ndf_covid19_response: Government response metrics (stringency index)\ndf_vaccine: Vaccination data"
  },
  {
    "objectID": "data-cleaning.html#export-cleaned-data",
    "href": "data-cleaning.html#export-cleaned-data",
    "title": "Data Cleaning Process",
    "section": "",
    "text": "At the time of documenting, I exported the unmerged data, if you would like to perform some analysis on your own with it. You should be able to see it in my github repo as `df.main.csv` file.\n\n\nCode\ndir = \"./exported-data\"\n\nif (!dir.exists(dir))\n{\n  dir.create(dir)\n}\n\ndf_covid19 &lt;- write.csv(x = df_covid19, file = paste0(dir, \"/\", \"df-covid19.csv\"))\ndf_covid19_response &lt;- write.csv(x = df_covid19_response, file=paste0(dir, \"/\", \"df-covid19-response.csv\"))\ndf_gdp &lt;- write.csv(x = df_gdp, file = paste0(dir, \"/\", \"df-gdp.csv\"))\ndf_pop &lt;- write.csv(x = df_pop, file = paste0(dir, \"/\", \"df-pop.csv\"))\ndf_vaccine &lt;- write.csv(x = df_vaccine, file = paste0(dir, \"/\", \"df-vaccine.csv\"))"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "EDA Process",
    "section": "",
    "text": "This page is a continuation of the previous section and outlines the EDA process performed for this COVID-19 analysis in the United States. In this section, we’ll create new columns for the 7 day moving average for each numerical table from df.main. Using a 7 day moving average helps smooth out the jumps we will have in the plots without the moving instance. There will be a varietry of plots I created here before getting there, and I will expand more on that in the sections below.\n\n\n\n\n\nI made a few plots here just to kind of get a rough view of what the data across each state by region and on the state-level. I wanted to get a feel for the total number of infections and deaths and to see the records in a map. This steps don’t essentially finalize anything. I just wanted a rough view on one or a few states before and while answering real questions.\n\n\nNext, we can check for missing values across all datasets:\n\n\nCode\n# Check missing values per column in all datasets\ndf_list &lt;- list(\n  df_covid19 = df_covid19, \n  df_gdp = df_gdp,\n  df_pop = df_pop,\n  df_covid19_response = df_covid19_response,\n  df_vaccine = df_vaccine\n)\n\nlapply(df_list, countNA)  # Custom function to count NAs\n\n\n# A tibble: 22 × 3\n   col              NAs NA_perc\n   &lt;chr&gt;          &lt;int&gt;   &lt;dbl&gt;\n 1 ...1               0    0   \n 2 date               0    0   \n 3 state              0    0   \n 4 country_region     0    0   \n 5 last_update       19    0.08\n 6 lat              874    3.52\n 7 long             874    3.52\n 8 confirmed          0    0   \n 9 deaths             0    0   \n10 recovered       9720   39.1 \n# ℹ 12 more rows\n# A tibble: 4 × 3\n  col              NAs NA_perc\n  &lt;chr&gt;          &lt;int&gt;   &lt;dbl&gt;\n1 ...1               0       0\n2 state              0       0\n3 gdp_nominal        0       0\n4 gdp_per_capita     0       0\n# A tibble: 3 × 3\n  col     NAs NA_perc\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 ...1      0       0\n2 state     0       0\n3 pop       0       0\n# A tibble: 13 × 3\n   col                                     NAs NA_perc\n   &lt;chr&gt;                                 &lt;int&gt;   &lt;dbl&gt;\n 1 ...1                                      0    0   \n 2 state                                   529    1.92\n 3 date                                      0    0   \n 4 stringency_index                        392    1.43\n 5 stringency_index_for_display            117    0.43\n 6 stringency_legacy_index                 380    1.38\n 7 stringency_legacy_index_for_display     105    0.38\n 8 government_response_index               424    1.54\n 9 government_response_index_for_display   149    0.54\n10 containment_health_index                411    1.49\n11 containment_health_index_for_display    136    0.49\n12 economic_support_index                  503    1.83\n13 economic_support_index_for_display      222    0.81\n# A tibble: 4 × 3\n  col            NAs NA_perc\n  &lt;chr&gt;        &lt;int&gt;   &lt;dbl&gt;\n1 ...1             0       0\n2 state            0       0\n3 date             0       0\n4 vaccinations     0       0\n\n\n$df_covid19\n\n\n\n\n\n\n\n\n\n\n$df_gdp\n\n\n\n\n\n\n\n\n\n\n$df_pop\n\n\n\n\n\n\n\n\n\n\n$df_covid19_response\n\n\n\n\n\n\n\n\n\n\n$df_vaccine\n\n\n\n\n\n\n\n\n\nKey findings: + Vaccination data contained 14,050 missing entries handled via imputation + COVID-19 recovery/active cases showed inconsistent reporting patterns + All other datasets had complete key variables\n\n\n\nWe can do this using checkTimeSpan custom function from previous page.\n\n\nCode\n# check time span for each data frame:\ncheckTimeSpan(df_covid19) # Puerto Rico is not a state\n\n\n# A tibble: 1 × 4\n  distinct_dates min_date   max_date   date_range\n           &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;    \n1            428 2020-04-12 2021-06-13 427 days  \n\n\n\n\n\n\n\n\n\nCode\ncheckTimeSpan(df_covid19_response)\n\n\n# A tibble: 1 × 4\n  distinct_dates min_date   max_date   date_range\n           &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;    \n1            529 2020-01-01 2021-06-12 528 days  \n\n\n\n\n\n\n\n\n\nCode\ncheckTimeSpan(df_vaccine)\n\n\n# A tibble: 1 × 4\n  distinct_dates min_date   max_date   date_range\n           &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;    \n1            173 2020-12-21 2021-06-11 172 days  \n\n\n\n\n\n\n\n\n\n\n\n\nEnsured consistent state naming across datasets using fuzzy string matching:\n\n\nCode\n## national level:\ndf_covid19 %&gt;% \n  select(state, date, confirmed:active) %&gt;% \n  # convert from long to wide:\n  pivot_longer(data =.,\n               cols = c(\"confirmed\", \"deaths\", \"recovered\", \"active\"),\n               names_to = \"variable\",\n               values_to = \"values\") %&gt;% \n  # aggregate on a date and variable level:\n  group_by(date, variable) %&gt;% \n  reframe(values = sum(values, na.rm = T)) %&gt;% \n  #plot:\n  ggplot(mapping = aes(x = date, \n                       y = values, \n                       color = variable)) +\n  geom_point(alpha = 0.7) +\n  facet_grid(variable ~. , scales = \"free\")\n\n\n\n\n\n\n\n\n\nCode\n# Observation from total number of cases on state and national level: All data regarding covid-19 infections are reported as running total.\"confirmed\" and \"deaths\"  cases seem to be reported consistently, however, there are missing data and in some parts a drop of reported data in \"recovered\" and \"active\" cases.\n\n\n\n# Step 1: Get a list of us state names:\nstates_list &lt;- tibble(state_base = datasets::state.name)\n\n## do state names matching with function in funcs.R\nstates_list_covid19 &lt;- matchStates(data = df_covid19, \n                                   col_name = \"state_covid19\")\n\n\n# A tibble: 50 × 2\n   states_base state_covid19\n   &lt;fct&gt;       &lt;fct&gt;        \n 1 Alabama     Alabama      \n 2 Alaska      Alaska       \n 3 Arizona     Arizona      \n 4 Arkansas    Arkansas     \n 5 California  California   \n 6 Colorado    Colorado     \n 7 Connecticut Connecticut  \n 8 Delaware    Delaware     \n 9 Florida     Florida      \n10 Georgia     Georgia      \n# ℹ 40 more rows\n\n\nCode\nstates_list_gdp &lt;- matchStates(data = df_covid19,\n                                   col_name = \"state_gdp\")\n\n\n# A tibble: 50 × 2\n   states_base state_gdp  \n   &lt;fct&gt;       &lt;fct&gt;      \n 1 Alabama     Alabama    \n 2 Alaska      Alaska     \n 3 Arizona     Arizona    \n 4 Arkansas    Arkansas   \n 5 California  California \n 6 Colorado    Colorado   \n 7 Connecticut Connecticut\n 8 Delaware    Delaware   \n 9 Florida     Florida    \n10 Georgia     Georgia    \n# ℹ 40 more rows\n\n\nCode\nstates_list_pop &lt;- matchStates(data = df_covid19,\n                                   col_name = \"state_pop\")\n\n\n# A tibble: 50 × 2\n   states_base state_pop  \n   &lt;fct&gt;       &lt;fct&gt;      \n 1 Alabama     Alabama    \n 2 Alaska      Alaska     \n 3 Arizona     Arizona    \n 4 Arkansas    Arkansas   \n 5 California  California \n 6 Colorado    Colorado   \n 7 Connecticut Connecticut\n 8 Delaware    Delaware   \n 9 Florida     Florida    \n10 Georgia     Georgia    \n# ℹ 40 more rows\n\n\nCode\nstates_list_covid19_response &lt;- matchStates(data = df_covid19,\n                                            col_name =\n                                          \"state_covid19_response\")\n\n\n# A tibble: 50 × 2\n   states_base state_covid19_response\n   &lt;fct&gt;       &lt;fct&gt;                 \n 1 Alabama     Alabama               \n 2 Alaska      Alaska                \n 3 Arizona     Arizona               \n 4 Arkansas    Arkansas              \n 5 California  California            \n 6 Colorado    Colorado              \n 7 Connecticut Connecticut           \n 8 Delaware    Delaware              \n 9 Florida     Florida               \n10 Georgia     Georgia               \n# ℹ 40 more rows\n\n\nCode\nstates_list_vaccine &lt;- matchStates(data = df_covid19,\n                                   col_name = \"state_vaccine\")\n\n\n# A tibble: 50 × 2\n   states_base state_vaccine\n   &lt;fct&gt;       &lt;fct&gt;        \n 1 Alabama     Alabama      \n 2 Alaska      Alaska       \n 3 Arizona     Arizona      \n 4 Arkansas    Arkansas     \n 5 California  California   \n 6 Colorado    Colorado     \n 7 Connecticut Connecticut  \n 8 Delaware    Delaware     \n 9 Florida     Florida      \n10 Georgia     Georgia      \n# ℹ 40 more rows\n\n\nCode\n# Create a universal list by joining the lists:\nstates_list &lt;- states_list_covid19 %&gt;% \n  inner_join(x = .,\n             y = states_list_gdp,\n             by = \"states_base\") %&gt;% \n  inner_join(x = .,\n             y = states_list_pop,\n             by = \"states_base\") %&gt;% \n  inner_join(x = .,\n             y = states_list_covid19_response,\n             by = \"states_base\") %&gt;% \n  inner_join(x = .,\n             y = states_list_vaccine,\n             by = \"states_base\") %&gt;% \n  arrange(states_base) %&gt;% \n  mutate(state_id = row_number()) %&gt;% \n  select(state_id, everything())\n\n\n# easier fix::\ndf_states_list &lt;- list(\n  states_list_covid19 = states_list_covid19,\n  states_list_covid19_response = states_list_covid19_response,\n  states_list_gdp = states_list_gdp,\n  states_list_pop = states_list_pop,\n  states_list_vaccine = states_list_vaccine)\n\nstates_list &lt;- reduce(.x = df_states_list, \n                      .f = inner_join,\n                      by = \"states_base\") %&gt;% \n  arrange(states_base) %&gt;% \n  mutate(state_id = row_number()) %&gt;% \n  select(state_id, everything())\n\n\n# All states are properly matched\n\n# Next, add state region\nstates_region &lt;- tibble(states_base = state.name,\n                        region = state.region)\n\n\n## create states table: \ndf_states &lt;- states_list %&gt;% \n  left_join(x = .,\n            y = states_region,\n            by = \"states_base\")\n\n\nResult:\n\nCreated master state list with standardized names and IDs\nRemoved non-state territories (e.g., Puerto Rico)\n\n\n\n\n\n\nCode\n## Get relevant dates:\ndf_dates &lt;- tibble(date = seq.Date(from = df_covid19 %&gt;% \n                                     pull(date) %&gt;% \n                                     min(.),\n                                   to = df_covid19 %&gt;% \n                                     pull(date) %&gt;% max(.),\n                                   by = \"1 day\"))\n\n## Create Main table:\ndf_main &lt;- df_states %&gt;% \n  # cross join:\n  cross_join(x = .,\n            y = df_dates)\n\n\n## cehck:\ndf_main %&gt;% \n  count(states_base) %&gt;% as.data.frame()\n\n\n      states_base   n\n1         Alabama 428\n2          Alaska 428\n3         Arizona 428\n4        Arkansas 428\n5      California 428\n6        Colorado 428\n7     Connecticut 428\n8        Delaware 428\n9         Florida 428\n10        Georgia 428\n11         Hawaii 428\n12          Idaho 428\n13       Illinois 428\n14        Indiana 428\n15           Iowa 428\n16         Kansas 428\n17       Kentucky 428\n18      Louisiana 428\n19          Maine 428\n20       Maryland 428\n21  Massachusetts 428\n22       Michigan 428\n23      Minnesota 428\n24    Mississippi 428\n25       Missouri 428\n26        Montana 428\n27       Nebraska 428\n28         Nevada 428\n29  New Hampshire 428\n30     New Jersey 428\n31     New Mexico 428\n32       New York 428\n33 North Carolina 428\n34   North Dakota 428\n35           Ohio 428\n36       Oklahoma 428\n37         Oregon 428\n38   Pennsylvania 428\n39   Rhode Island 428\n40 South Carolina 428\n41   South Dakota 428\n42      Tennessee 428\n43          Texas 428\n44           Utah 428\n45        Vermont 428\n46       Virginia 428\n47     Washington 428\n48  West Virginia 428\n49      Wisconsin 428\n50        Wyoming 428\n\n\nCode\ndf_main &lt;- df_main %&gt;%\n  mutate(across(states_base:state_vaccine, str_trim))\n\ndf_covid19 &lt;- df_covid19 %&gt;%\n  mutate(state = str_trim(state))\n\ndf_gdp &lt;- df_gdp %&gt;%\n  mutate(state = str_trim(state))\n\ndf_pop &lt;- df_pop %&gt;%\n  mutate(state = str_trim(state))\n\ndf_covid19_response &lt;- df_covid19_response %&gt;%\n  mutate(state = str_trim(state))\n\ndf_vaccine &lt;- df_vaccine %&gt;%\n  mutate(state = str_trim(state))\n\ndf_joined &lt;- df_main %&gt;% \n  left_join(x = .,\n            y = df_covid19 %&gt;% select(state, date, \n                                      confirmed, deaths),\n            by = c(\"state_covid19\" = \"state\",\n                   \"date\" = \"date\")) %&gt;% \n  left_join(x = .,\n            y = df_gdp,\n            by = c(\"state_gdp\" = \"state\")) %&gt;% \n  left_join(x = .,\n            y = df_pop,\n            by = c(\"state_pop\" = \"state\")) %&gt;% \n  left_join(x = .,\n            y = df_vaccine,\n            by = c(\"state_vaccine\" = \"state\",\n                   \"date\" = \"date\")) %&gt;% \n  left_join(x = .,\n            y = df_covid19_response,\n            by = c(\"state_covid19_response\" = \"state\",\n                   \"date\" = \"date\")) %&gt;% \n  # remove redundant columns:\n  select(-c(\"state_covid19\", \"state_gdp\", \n            \"state_vaccine\", \"state_vaccine\", \"state_pop\")) %&gt;% \n  # re-arrange:\n  select(state_id,\n         state = states_base,\n         region,\n         date,\n         confirmed_total = confirmed,\n         deaths_total = deaths,\n         daily_vacc_doses = vaccinations,\n         population = pop,\n         everything()) %&gt;% \n  arrange(state, date)\n\n\n\ndf.main &lt;- df_joined\n\n\nResult:\n\nCreates a sequence of dates from minimum to maximum date sequence.\nCreates the main table using a cross join on the states list and the date sequence created.\nI removed the leading and trailing white spaces in the state names for the 5 primary datasets.\n\n- I had a wrong result merging without doing this step.\nHow come? I found that some records were overlooked and not properly match which was quite odd because I thought R automatically trims white spaces in character vectors when you import the data.\nMy solution: I took the preventative step of removing the white-spaces.\nI realized it was important to remove the trailing white spaces to preveent wrong merging results in textual data.\n\nMerges the 5 thoroughly cleaned data-sets to the df.main (main) table that will be used for data analysis.\n\n\n\n\n\nCode\n## check for missing data for non-vaccination data:\ndf.main %&gt;% \n  filter(is.na(confirmed_total)) %&gt;%  # to check for missing values\n  nrow()  # count the number of rows for missing values\n\n\n[1] 0\n\n\nCode\ndf.main %&gt;% \n  filter(is.na(deaths_total)) %&gt;%  # to check for missing values\n  nrow() \n\n\n[1] 0\n\n\nCode\n# Get vaccination starting date:\ndf.main %&gt;% \n  filter(is.na(daily_vacc_doses)) %&gt;% nrow()\n\n\n[1] 14050\n\n\nCode\n# There are 14050 missing data for vaccination doses.\n\n\n# Get the minimum date for non-missing values of vaccination doses\ndf_state_vaccDatesMin &lt;- df.main %&gt;% \n  filter(!is.na(daily_vacc_doses)) %&gt;% \n  group_by(state) %&gt;% \n  reframe(min_date = min(date)) %&gt;% \n  summarise(min_date = min(min_date))\n\n\n## replace NAs, calculate daily counts and total counts\ndf.main &lt;- df.main %&gt;% \n  mutate(population_in_mil = round(population / 10e6, 2),\n         daily_vacc_doses = replace_na(daily_vacc_doses, \n                                       replace = 0)) %&gt;%\n  # get daily count:\n  group_by(state) %&gt;% \n  mutate(confirmed_daily_cases = \n           confirmed_total - lag(confirmed_total, n = 1),\n         death_daily_cases = \n             deaths_total - lag(deaths_total, n = 1)) %&gt;% \n  mutate(vaccine_doses_total = cumsum(daily_vacc_doses)) %&gt;% \n  ungroup() %&gt;% \n  select(state_id:date,\n         confirmed_total, confirmed_daily_cases,\n         deaths_total, death_daily_cases,\n         vaccine_doses_total, daily_vacc_doses,\n         everything())\n\n\n## check for negative values and replace them with zero, because some data were not reported:\ndf.main &lt;- df.main %&gt;% \n  mutate_at(.tbl = .,\n            .vars = c(\"confirmed_daily_cases\", \n                      \"death_daily_cases\", \"vaccine_doses_total\"),\n            .funs = function(.vars) {ifelse(.vars &lt; 0, 0, .vars)}) \n\n\nResult:\n\nSince I used left-join, I expected some Missing Values on the merged records.\nPerhaps I should have used inner join, however, I wanted to account for days where the states failed to record the cases, thereby catching the inconsistencies and noting them in the EDA.\nBecause we replaced missing records with 0, I suspected performing a lag for confirmed_total, deaths_total and vaccine_doses_total, would cause some negative values which means there was a drop in the report from the states.\nI replaced these negative values with 0 since you cannot quantify that you had negative number of reported cases. This doesn’t really make sense to others unless you’re being mathematical.\n\n\n\n\n\n\n\nCode\n## Get total number of infections and deaths:\n# - states per region\ndf.main %&gt;% \n  group_by(region) %&gt;% \n  reframe(states = n_distinct(state),\n          total_death = sum(deaths_total),\n          confirmed_total = sum(confirmed_total))\n\n\n# A tibble: 4 × 4\n  region        states total_death confirmed_total\n  &lt;fct&gt;          &lt;int&gt;       &lt;dbl&gt;           &lt;dbl&gt;\n1 Northeast          9    38364209      1081429125\n2 South             16    44545840      2571405091\n3 North Central     12    26293166      1424039247\n4 West              13    22062974      1428613518\n\n\nCode\n## show states on map:\nmax_date &lt;- df.main %&gt;% pull(date) %&gt;% max(.)\n\n## states to lower case:\ndf.main &lt;- df.main %&gt;% \n  mutate(state_ = str_to_lower(string = state))\n\n\ndf.main %&gt;% \n  filter(date == max_date) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = group)) +\n  geom_polygon(aes(fill = region),\n               color = \"black\") +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\n\n\n\nResults:\n\nHere, I wanted to get a rough feel for the total number of infections and deaths by region and I used a map to see that.\n\n\n\n\n\nHere, we want to look at the total number of confirmed cases as they change over time.\n\n\nCode\n## Get relative counts:\ndf.main &lt;- df.main %&gt;% \n  mutate(confirmed_totalPerc = confirmed_total / population,\n          deaths_totalPerc = deaths_total / population)\n  \n\n ## add region groups:\ndf_regionGroup &lt;- df.main %&gt;% \n  group_by(region) %&gt;% \n  count(state) %&gt;% \n  ungroup() %&gt;% \n  arrange(region, state) %&gt;% \n  # add state count:\n  group_by(region) %&gt;% \n  mutate(states = n(),\n         id = row_number()) %&gt;% \n  ungroup() %&gt;% \n  # add group id:\n  mutate(group = case_when(id &lt;= round(states / 2, 0) ~ 1, \n                           T ~ 2)) %&gt;% \n  mutate(region_group = paste(region, \"- group\", group, sep = \" \")) %&gt;% \n  select(state, region_group)\n\n\n\n## bring groups to main table:\ndf.main &lt;- df.main %&gt;%\n  left_join(x = .,\n            y = df_regionGroup,\n            by = \"state\")\n\n## Plot:\nregion_group &lt;- df_regionGroup %&gt;% \n  distinct(region_group) %&gt;% \n  pull(region_group)\n\n#plotConfirmedCasesTotal(region.group = \"Northeast - group 1\")  \n\n## Plot for each region and group:\nregion_group\n\n\n[1] \"Northeast - group 1\"     \"Northeast - group 2\"    \n[3] \"South - group 1\"         \"South - group 2\"        \n[5] \"North Central - group 1\" \"North Central - group 2\"\n[7] \"West - group 1\"          \"West - group 2\"         \n\n\nCode\nmap(.x = region_group, .f = ~plotConfirmedCasesTotal(region.group = .x))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[[1]]\n[1] \"./explore/01_confirmed_cases_and_deaths Northeast - group 1 .png\"\n\n[[2]]\n[1] \"./explore/01_confirmed_cases_and_deaths Northeast - group 2 .png\"\n\n[[3]]\n[1] \"./explore/01_confirmed_cases_and_deaths South - group 1 .png\"\n\n[[4]]\n[1] \"./explore/01_confirmed_cases_and_deaths South - group 2 .png\"\n\n[[5]]\n[1] \"./explore/01_confirmed_cases_and_deaths North Central - group 1 .png\"\n\n[[6]]\n[1] \"./explore/01_confirmed_cases_and_deaths North Central - group 2 .png\"\n\n[[7]]\n[1] \"./explore/01_confirmed_cases_and_deaths West - group 1 .png\"\n\n[[8]]\n[1] \"./explore/01_confirmed_cases_and_deaths West - group 2 .png\"\n\n\nFeatures and Outputs:\n\nI created new columns for relative counts in percentage by dividing the infection and deaths total by the population.\nI added a region group column for each region, so I can properly categorize by each region. It felt easier for me this way.\nThen I created a plot for each region’s group to track the pandemic’s progression for each region.\n\n\n\n\n\n\nCode\n## bar chart:\nplot &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, state, confirmed_totalPerc, deaths_totalPerc) %&gt;% \n  rename(`confirmed total %` = confirmed_totalPerc, \n         `death total %` = deaths_totalPerc) %&gt;% \n  # convert from wide to long:\n  pivot_longer(cols = c(`confirmed total %`, `death total %`),\n               names_to = \"percentage\",\n               values_to = \"values\") %&gt;% \n  group_by(state) %&gt;% \n  mutate(total_perc = sum(values)) %&gt;% \n  ungroup() %&gt;% \n  arrange(total_perc, state) %&gt;% \n  mutate(state = as.factor(state)) %&gt;% \n  mutate(state = fct_inorder(state)) %&gt;% \n  ggplot(mapping = aes(x = values,\n                       y = state,\n                       fill = region)) +\n  geom_col(color = \"black\") +\n  facet_wrap(percentage ~ .,\n             scales = \"free\") + \n  xlab(\"Percentage of State Population\") +\n  ylab(\"State\") +\n  ggtitle(\"Barplot of Confirmed Cases and Deaths for Each State\") +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\ndir = \"./explore\"\nif (!dir.exists(dir))\n{\n    dir.create(dir)\n}\n\n# export plot:\nggsave(filename = \n         \"./explore/02_Barplot_of_Confirmed_Cases_and_Deaths_Per_State.png\",\n       plot = plot,\n       width = 30,\n       height = 25,\n       units = \"cm\")\n\n\n\ndf_samp &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, region_group, state, state_, confirmed_totalPerc, deaths_totalPerc) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  rename(`confirmed total %` = confirmed_totalPerc, \n         `death total %` = deaths_totalPerc) %&gt;% \n  pivot_longer(cols = c(`confirmed total %`, `death total %`),\n               names_to = \"percentage\",\n               values_to = \"values\") %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = state)) +\n  geom_polygon(aes(fill = values),\n               color = \"black\",\n               show.legend = T) +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank()) + \n  scale_fill_viridis_c(option = \"inferno\")\n\n\n## Create a map regarding relative counts:\ndf.main &lt;- df.main %&gt;% \n  rename(`confirmed total %` = confirmed_totalPerc, \n         `death total %` = deaths_totalPerc)\n\n\np2 &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, state_, state, `confirmed total %`, `death total %`) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = state)) +\n  geom_polygon(aes(fill = `confirmed total %`),\n               color = \"black\",\n               show.legend = T) +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"Percentage of Confirmed Cases for Each State Population\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank()) + \n  scale_fill_viridis_c(option = \"inferno\")\n\n\np1 &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, state_, state, `confirmed total %`, `death total %`) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = state)) +\n  geom_polygon(aes(fill = `death total %`),\n               color = \"black\",\n               show.legend = T) +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"Percentage of Death Cases for Each State Population\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank()) + \n  scale_fill_gradient(low = \"white\", high = \"black\")\n\nplot &lt;- plot_grid(p1, p2, nrow = 2)\n\n# export plot:\nggsave(filename = \n         \"./explore/02_Map_of_Confirmed_Cases_and_Deaths_Per_State.png\",\n       plot = plot,\n       width = 30,\n       height = 25,\n       units = \"cm\")\n\n\nResults:\n\nBar charts are created here for relative counts in percentage of death cases and infection for each state population.\nMaps are also created to see the percentage across all states using a continuous scale for the color.\nPlots are then saved to ./explore directory.\n\n\n\n\nHere, we want to look at how daily confirmed cases and deaths change over time. Essentially, we’ll be performed a time series. The plot in the code block below will have jumps that we will smoothen out in the second code block. The first is kind of to see for ourselves the jags, which will help us realize the need for a moving average!\n\n\nCode\ndf.main %&gt;% \n  group_by(state, date) %&gt;% \n  arrange(state, date) %&gt;% \n  mutate_at(.tbl = .,\n            .vars = c(\"confirmed_daily_cases\", \"death_daily_cases\"),\n            .funs = function(x){ifelse(is.na(x), 0, x)}) %&gt;% \n  pivot_longer(data = .,\n               cols = c(\"confirmed_daily_cases\", \"death_daily_cases\"),\n               names_to = \"daily_cases\",\n               values_to = \"values\") %&gt;% \n  ggplot(mapping = aes(x = date,\n                       y = values,\n                       color = daily_cases)) +\n  geom_line(show.legend = F) + \n  facet_wrap(region ~ ., scales = \"free\")\n\n\n\n\n\n\n\n\n\nResults:\n\nHere, you will see that our first time series have jumps since missing values and negative were replaced with zeros earlier in the data cleaning because there were inconsistencies in the reporting of data by states.\nInstead, we use a moving average to smooth out these jumps.\n\n\n\nCode\nlibrary(zoo)\n\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  group_by(state) %&gt;% \n  mutate( across( .cols = c(confirmed_daily_cases, death_daily_cases),\n                  ~ rollapply(data = ., width = 7, FUN = mean, fill = NA, \n                              align = \"right\", na.rm = TRUE),\n      .names = \"{.col} 7d Avg\")) %&gt;% \n  ungroup()\n\n\n\n\n\n\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  group_by(state) %&gt;% \n  mutate( across( .cols = c(confirmed_daily_cases, death_daily_cases),\n                  ~ rollapply(data = ., width = 7, FUN = mean, fill = NA, \n                              align = \"right\", na.rm = TRUE),\n      .names = \"{.col} 7d Avg\")) %&gt;% \n  ungroup()\n\n# data validation \ndf.main %&gt;% \n  filter(is.na(`confirmed_daily_cases 7d Avg`)) %&gt;% \n  select(`confirmed_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\ndf.main %&gt;% \n  filter(is.na(`death_daily_cases 7d Avg`)) %&gt;% \n  select(`death_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\n# Data validation here: check for missing values\ndf.main %&gt;% \n  filter(is.na(`confirmed_daily_cases 7d Avg`)) %&gt;% \n  select(`confirmed_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\ndf.main %&gt;% \n  filter(is.na(`death_daily_cases 7d Avg`)) %&gt;% \n  select(`death_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\n# Plot for each region:\ndf.main %&gt;% \n  pivot_longer(data = .,\n               cols =\n                 c(`confirmed_daily_cases 7d Avg`, `death_daily_cases 7d Avg`),\n               names_to = \"daily_cases\",\n               values_to = \"values\") %&gt;% \n  ggplot(mapping = aes(x = date,\n                       y = values,\n                       color = daily_cases)) +\n  geom_line(show.legend = F, alpha = 0.7) + \n  scale_fill_viridis_d() +\n  facet_wrap(region ~ ., scales = \"free\")\n\n\n\n\n\n\n\n\n\nCode\n# Plot:\nmap(.x = region_group, \n    .f = ~ plot7DayAverage(region.group = .x))\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\nFeatures:\n\nWe added a 7 day moving average columns for the confirmed_daily_cases and death_daily_cases to the df.main\nThen we did data validation to check for missing values in the moving averages. We should expect No missing values in the moving average, because the essence of the moving average is to smooth out the jumps in the time series.\nThe plot returned from the code block should show the smoothed time series for the pandemic dynamics.\n\n\n\n\nI’ll reframe a bit: Do state wealth and/or state population have an effect on total percentage of confirmed cases and deaths?\nThough we cannot say it DOES, but plotting the scatterplot will show if there is some kind of relationship that we can notice ourselves.\n\n\nCode\nplot &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  ggplot(aes(x = `confirmed total %`,\n             y = `death total %`,\n             size = population_in_mil,\n             color = gdp_per_capita)) +\n  geom_point(alpha = 0.75,\n             show.legend = T) +\n  facet_wrap(. ~ region, scales = \"free\") +\n  scale_color_gradient(low=\"brown1\", high=\"green\") +\n  scale_size_area(max_size = 30) +\n  theme_minimal() +\n  xlab(\"Total Confirmed Cases %\") +\n  ylab(\"Total Deaths %\") +\n  ggtitle(\"Total Confirmed Cases and Total Deaths % VS GDP and population\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\nfilename &lt;- file.path(paste0(\"./explore/04_total_confirmed_deaths_perc_gdp_pop_and_scatter.png\"))\n\n# Save plot\nggsave(filename = filename,\n       plot = plot,\n       width = 35, height = 25, units = \"cm\",\n       dpi = 1200)\n\n\nFeatures:\n\nWe plot scatter-plots to try to visualize the relationship.\nThese plots are saved in the ./explore directory as well.\n\n\n\n\n\n\nCode\nmap(.x = region_group,\n    .f = ~ plot_vaccineDosesTotal_7DayAVg(region.group = .x))\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\nFeatures:\n\nHere, we plot the moving averages of the cummulative sum of vaccine doses already calculated from before to see the trend of the does, confirmed cases and death toll.\n\n\n\n\nHere we show on map how number of COVID-case have changed over time (monthly).\n\n\nCode\n# add date id and snapshot flag\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  # date id per state:\n  group_by(state) %&gt;% \n  mutate(date_id = row_number()) %&gt;% \n  ungroup() %&gt;% \n  # add date snapshot flag for every 30th day:\n  mutate(date_snapshot_flag = case_when(date_id == 1 ~ TRUE,\n                                       date_id == max_date ~ TRUE,\n                                       date_id %% 30 == 0 ~ TRUE,\n                                       TRUE ~ FALSE))\n\n# plot the maps:\nvariables &lt;- c(\"confirmed_total\", \"deaths_total\", \"vaccine_doses_total\")\n\nplots &lt;- map(variables, ~ plotCovid19Map_overTime(df.main, .x))\n\n\nFeatures:\n\nA new columns for the date flag for every 30th day (month) is created.\nStacked area charts of covid 19 indicators in a log-scale time series are shown, as well as the government response metrics.\n\n\n\n\nWe sort by state, date then the stringency index, grouping by state and seeing the stacked area charts of the stringency index for display.\n\n\nCode\nwStringencyIndex &lt;- df.main %&gt;% \n  arrange(state, date, stringency_index_for_display) %&gt;% \n  # date id per state:\n  group_by(state) %&gt;% \n  mutate(date_id = row_number()) %&gt;% \n  ungroup() %&gt;% \n  # add date snapshot flag for every 30th day:\n  mutate(date_snapshot_flag = case_when(date_id == 1 ~ TRUE,\n                                        date_id == max_date ~ TRUE,\n                                        date_id %% 30 == 0 ~ TRUE,\n                                        TRUE ~ FALSE))\n\nplots &lt;- map(\"stringency_index_for_display\",\n             ~ plotCovid19Map_overTime(df.main, .x))\n\n\n\n\n\nHere we look at the vaccine smoothed daily counts by creating first the 7 day moving average column and plotting for some states here: California, Texas, New York are used as examples.\n\n\nCode\n## vaccine smoothed daily counts:\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  group_by(state) %&gt;% \n  mutate(across( .cols = daily_vacc_doses,\n                  ~ rollapply(data = ., width = 7, FUN = mean, fill = NA, \n                              align = \"right\", na.rm = TRUE),\n                 .names = \"{.col} 7d Avg\")) %&gt;% \n  ungroup()\n\n\n\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"California\")\n\n\n\n\n\n\n\n\n\nCode\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"New York\")\n\n\n\n\n\n\n\n\n\nCode\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"Texas\")\n\n\n\n\n\n\n\n\n\nCode\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"Nebraska\")"
  },
  {
    "objectID": "eda.html#a-few-graphs-before-getting-serious",
    "href": "eda.html#a-few-graphs-before-getting-serious",
    "title": "EDA Process",
    "section": "",
    "text": "I made a few plots here just to kind of get a rough view of what the data across each state by region and on the state-level. I wanted to get a feel for the total number of infections and deaths and to see the records in a map. This steps don’t essentially finalize anything. I just wanted a rough view on one or a few states before and while answering real questions.\n\n\nNext, we can check for missing values across all datasets:\n\n\nCode\n# Check missing values per column in all datasets\ndf_list &lt;- list(\n  df_covid19 = df_covid19, \n  df_gdp = df_gdp,\n  df_pop = df_pop,\n  df_covid19_response = df_covid19_response,\n  df_vaccine = df_vaccine\n)\n\nlapply(df_list, countNA)  # Custom function to count NAs\n\n\n# A tibble: 22 × 3\n   col              NAs NA_perc\n   &lt;chr&gt;          &lt;int&gt;   &lt;dbl&gt;\n 1 ...1               0    0   \n 2 date               0    0   \n 3 state              0    0   \n 4 country_region     0    0   \n 5 last_update       19    0.08\n 6 lat              874    3.52\n 7 long             874    3.52\n 8 confirmed          0    0   \n 9 deaths             0    0   \n10 recovered       9720   39.1 \n# ℹ 12 more rows\n# A tibble: 4 × 3\n  col              NAs NA_perc\n  &lt;chr&gt;          &lt;int&gt;   &lt;dbl&gt;\n1 ...1               0       0\n2 state              0       0\n3 gdp_nominal        0       0\n4 gdp_per_capita     0       0\n# A tibble: 3 × 3\n  col     NAs NA_perc\n  &lt;chr&gt; &lt;int&gt;   &lt;dbl&gt;\n1 ...1      0       0\n2 state     0       0\n3 pop       0       0\n# A tibble: 13 × 3\n   col                                     NAs NA_perc\n   &lt;chr&gt;                                 &lt;int&gt;   &lt;dbl&gt;\n 1 ...1                                      0    0   \n 2 state                                   529    1.92\n 3 date                                      0    0   \n 4 stringency_index                        392    1.43\n 5 stringency_index_for_display            117    0.43\n 6 stringency_legacy_index                 380    1.38\n 7 stringency_legacy_index_for_display     105    0.38\n 8 government_response_index               424    1.54\n 9 government_response_index_for_display   149    0.54\n10 containment_health_index                411    1.49\n11 containment_health_index_for_display    136    0.49\n12 economic_support_index                  503    1.83\n13 economic_support_index_for_display      222    0.81\n# A tibble: 4 × 3\n  col            NAs NA_perc\n  &lt;chr&gt;        &lt;int&gt;   &lt;dbl&gt;\n1 ...1             0       0\n2 state            0       0\n3 date             0       0\n4 vaccinations     0       0\n\n\n$df_covid19\n\n\n\n\n\n\n\n\n\n\n$df_gdp\n\n\n\n\n\n\n\n\n\n\n$df_pop\n\n\n\n\n\n\n\n\n\n\n$df_covid19_response\n\n\n\n\n\n\n\n\n\n\n$df_vaccine\n\n\n\n\n\n\n\n\n\nKey findings: + Vaccination data contained 14,050 missing entries handled via imputation + COVID-19 recovery/active cases showed inconsistent reporting patterns + All other datasets had complete key variables\n\n\n\nWe can do this using checkTimeSpan custom function from previous page.\n\n\nCode\n# check time span for each data frame:\ncheckTimeSpan(df_covid19) # Puerto Rico is not a state\n\n\n# A tibble: 1 × 4\n  distinct_dates min_date   max_date   date_range\n           &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;    \n1            428 2020-04-12 2021-06-13 427 days  \n\n\n\n\n\n\n\n\n\nCode\ncheckTimeSpan(df_covid19_response)\n\n\n# A tibble: 1 × 4\n  distinct_dates min_date   max_date   date_range\n           &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;    \n1            529 2020-01-01 2021-06-12 528 days  \n\n\n\n\n\n\n\n\n\nCode\ncheckTimeSpan(df_vaccine)\n\n\n# A tibble: 1 × 4\n  distinct_dates min_date   max_date   date_range\n           &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;drtn&gt;    \n1            173 2020-12-21 2021-06-11 172 days  \n\n\n\n\n\n\n\n\n\n\n\n\nEnsured consistent state naming across datasets using fuzzy string matching:\n\n\nCode\n## national level:\ndf_covid19 %&gt;% \n  select(state, date, confirmed:active) %&gt;% \n  # convert from long to wide:\n  pivot_longer(data =.,\n               cols = c(\"confirmed\", \"deaths\", \"recovered\", \"active\"),\n               names_to = \"variable\",\n               values_to = \"values\") %&gt;% \n  # aggregate on a date and variable level:\n  group_by(date, variable) %&gt;% \n  reframe(values = sum(values, na.rm = T)) %&gt;% \n  #plot:\n  ggplot(mapping = aes(x = date, \n                       y = values, \n                       color = variable)) +\n  geom_point(alpha = 0.7) +\n  facet_grid(variable ~. , scales = \"free\")\n\n\n\n\n\n\n\n\n\nCode\n# Observation from total number of cases on state and national level: All data regarding covid-19 infections are reported as running total.\"confirmed\" and \"deaths\"  cases seem to be reported consistently, however, there are missing data and in some parts a drop of reported data in \"recovered\" and \"active\" cases.\n\n\n\n# Step 1: Get a list of us state names:\nstates_list &lt;- tibble(state_base = datasets::state.name)\n\n## do state names matching with function in funcs.R\nstates_list_covid19 &lt;- matchStates(data = df_covid19, \n                                   col_name = \"state_covid19\")\n\n\n# A tibble: 50 × 2\n   states_base state_covid19\n   &lt;fct&gt;       &lt;fct&gt;        \n 1 Alabama     Alabama      \n 2 Alaska      Alaska       \n 3 Arizona     Arizona      \n 4 Arkansas    Arkansas     \n 5 California  California   \n 6 Colorado    Colorado     \n 7 Connecticut Connecticut  \n 8 Delaware    Delaware     \n 9 Florida     Florida      \n10 Georgia     Georgia      \n# ℹ 40 more rows\n\n\nCode\nstates_list_gdp &lt;- matchStates(data = df_covid19,\n                                   col_name = \"state_gdp\")\n\n\n# A tibble: 50 × 2\n   states_base state_gdp  \n   &lt;fct&gt;       &lt;fct&gt;      \n 1 Alabama     Alabama    \n 2 Alaska      Alaska     \n 3 Arizona     Arizona    \n 4 Arkansas    Arkansas   \n 5 California  California \n 6 Colorado    Colorado   \n 7 Connecticut Connecticut\n 8 Delaware    Delaware   \n 9 Florida     Florida    \n10 Georgia     Georgia    \n# ℹ 40 more rows\n\n\nCode\nstates_list_pop &lt;- matchStates(data = df_covid19,\n                                   col_name = \"state_pop\")\n\n\n# A tibble: 50 × 2\n   states_base state_pop  \n   &lt;fct&gt;       &lt;fct&gt;      \n 1 Alabama     Alabama    \n 2 Alaska      Alaska     \n 3 Arizona     Arizona    \n 4 Arkansas    Arkansas   \n 5 California  California \n 6 Colorado    Colorado   \n 7 Connecticut Connecticut\n 8 Delaware    Delaware   \n 9 Florida     Florida    \n10 Georgia     Georgia    \n# ℹ 40 more rows\n\n\nCode\nstates_list_covid19_response &lt;- matchStates(data = df_covid19,\n                                            col_name =\n                                          \"state_covid19_response\")\n\n\n# A tibble: 50 × 2\n   states_base state_covid19_response\n   &lt;fct&gt;       &lt;fct&gt;                 \n 1 Alabama     Alabama               \n 2 Alaska      Alaska                \n 3 Arizona     Arizona               \n 4 Arkansas    Arkansas              \n 5 California  California            \n 6 Colorado    Colorado              \n 7 Connecticut Connecticut           \n 8 Delaware    Delaware              \n 9 Florida     Florida               \n10 Georgia     Georgia               \n# ℹ 40 more rows\n\n\nCode\nstates_list_vaccine &lt;- matchStates(data = df_covid19,\n                                   col_name = \"state_vaccine\")\n\n\n# A tibble: 50 × 2\n   states_base state_vaccine\n   &lt;fct&gt;       &lt;fct&gt;        \n 1 Alabama     Alabama      \n 2 Alaska      Alaska       \n 3 Arizona     Arizona      \n 4 Arkansas    Arkansas     \n 5 California  California   \n 6 Colorado    Colorado     \n 7 Connecticut Connecticut  \n 8 Delaware    Delaware     \n 9 Florida     Florida      \n10 Georgia     Georgia      \n# ℹ 40 more rows\n\n\nCode\n# Create a universal list by joining the lists:\nstates_list &lt;- states_list_covid19 %&gt;% \n  inner_join(x = .,\n             y = states_list_gdp,\n             by = \"states_base\") %&gt;% \n  inner_join(x = .,\n             y = states_list_pop,\n             by = \"states_base\") %&gt;% \n  inner_join(x = .,\n             y = states_list_covid19_response,\n             by = \"states_base\") %&gt;% \n  inner_join(x = .,\n             y = states_list_vaccine,\n             by = \"states_base\") %&gt;% \n  arrange(states_base) %&gt;% \n  mutate(state_id = row_number()) %&gt;% \n  select(state_id, everything())\n\n\n# easier fix::\ndf_states_list &lt;- list(\n  states_list_covid19 = states_list_covid19,\n  states_list_covid19_response = states_list_covid19_response,\n  states_list_gdp = states_list_gdp,\n  states_list_pop = states_list_pop,\n  states_list_vaccine = states_list_vaccine)\n\nstates_list &lt;- reduce(.x = df_states_list, \n                      .f = inner_join,\n                      by = \"states_base\") %&gt;% \n  arrange(states_base) %&gt;% \n  mutate(state_id = row_number()) %&gt;% \n  select(state_id, everything())\n\n\n# All states are properly matched\n\n# Next, add state region\nstates_region &lt;- tibble(states_base = state.name,\n                        region = state.region)\n\n\n## create states table: \ndf_states &lt;- states_list %&gt;% \n  left_join(x = .,\n            y = states_region,\n            by = \"states_base\")\n\n\nResult:\n\nCreated master state list with standardized names and IDs\nRemoved non-state territories (e.g., Puerto Rico)\n\n\n\n\n\n\nCode\n## Get relevant dates:\ndf_dates &lt;- tibble(date = seq.Date(from = df_covid19 %&gt;% \n                                     pull(date) %&gt;% \n                                     min(.),\n                                   to = df_covid19 %&gt;% \n                                     pull(date) %&gt;% max(.),\n                                   by = \"1 day\"))\n\n## Create Main table:\ndf_main &lt;- df_states %&gt;% \n  # cross join:\n  cross_join(x = .,\n            y = df_dates)\n\n\n## cehck:\ndf_main %&gt;% \n  count(states_base) %&gt;% as.data.frame()\n\n\n      states_base   n\n1         Alabama 428\n2          Alaska 428\n3         Arizona 428\n4        Arkansas 428\n5      California 428\n6        Colorado 428\n7     Connecticut 428\n8        Delaware 428\n9         Florida 428\n10        Georgia 428\n11         Hawaii 428\n12          Idaho 428\n13       Illinois 428\n14        Indiana 428\n15           Iowa 428\n16         Kansas 428\n17       Kentucky 428\n18      Louisiana 428\n19          Maine 428\n20       Maryland 428\n21  Massachusetts 428\n22       Michigan 428\n23      Minnesota 428\n24    Mississippi 428\n25       Missouri 428\n26        Montana 428\n27       Nebraska 428\n28         Nevada 428\n29  New Hampshire 428\n30     New Jersey 428\n31     New Mexico 428\n32       New York 428\n33 North Carolina 428\n34   North Dakota 428\n35           Ohio 428\n36       Oklahoma 428\n37         Oregon 428\n38   Pennsylvania 428\n39   Rhode Island 428\n40 South Carolina 428\n41   South Dakota 428\n42      Tennessee 428\n43          Texas 428\n44           Utah 428\n45        Vermont 428\n46       Virginia 428\n47     Washington 428\n48  West Virginia 428\n49      Wisconsin 428\n50        Wyoming 428\n\n\nCode\ndf_main &lt;- df_main %&gt;%\n  mutate(across(states_base:state_vaccine, str_trim))\n\ndf_covid19 &lt;- df_covid19 %&gt;%\n  mutate(state = str_trim(state))\n\ndf_gdp &lt;- df_gdp %&gt;%\n  mutate(state = str_trim(state))\n\ndf_pop &lt;- df_pop %&gt;%\n  mutate(state = str_trim(state))\n\ndf_covid19_response &lt;- df_covid19_response %&gt;%\n  mutate(state = str_trim(state))\n\ndf_vaccine &lt;- df_vaccine %&gt;%\n  mutate(state = str_trim(state))\n\ndf_joined &lt;- df_main %&gt;% \n  left_join(x = .,\n            y = df_covid19 %&gt;% select(state, date, \n                                      confirmed, deaths),\n            by = c(\"state_covid19\" = \"state\",\n                   \"date\" = \"date\")) %&gt;% \n  left_join(x = .,\n            y = df_gdp,\n            by = c(\"state_gdp\" = \"state\")) %&gt;% \n  left_join(x = .,\n            y = df_pop,\n            by = c(\"state_pop\" = \"state\")) %&gt;% \n  left_join(x = .,\n            y = df_vaccine,\n            by = c(\"state_vaccine\" = \"state\",\n                   \"date\" = \"date\")) %&gt;% \n  left_join(x = .,\n            y = df_covid19_response,\n            by = c(\"state_covid19_response\" = \"state\",\n                   \"date\" = \"date\")) %&gt;% \n  # remove redundant columns:\n  select(-c(\"state_covid19\", \"state_gdp\", \n            \"state_vaccine\", \"state_vaccine\", \"state_pop\")) %&gt;% \n  # re-arrange:\n  select(state_id,\n         state = states_base,\n         region,\n         date,\n         confirmed_total = confirmed,\n         deaths_total = deaths,\n         daily_vacc_doses = vaccinations,\n         population = pop,\n         everything()) %&gt;% \n  arrange(state, date)\n\n\n\ndf.main &lt;- df_joined\n\n\nResult:\n\nCreates a sequence of dates from minimum to maximum date sequence.\nCreates the main table using a cross join on the states list and the date sequence created.\nI removed the leading and trailing white spaces in the state names for the 5 primary datasets.\n\n- I had a wrong result merging without doing this step.\nHow come? I found that some records were overlooked and not properly match which was quite odd because I thought R automatically trims white spaces in character vectors when you import the data.\nMy solution: I took the preventative step of removing the white-spaces.\nI realized it was important to remove the trailing white spaces to preveent wrong merging results in textual data.\n\nMerges the 5 thoroughly cleaned data-sets to the df.main (main) table that will be used for data analysis.\n\n\n\n\n\nCode\n## check for missing data for non-vaccination data:\ndf.main %&gt;% \n  filter(is.na(confirmed_total)) %&gt;%  # to check for missing values\n  nrow()  # count the number of rows for missing values\n\n\n[1] 0\n\n\nCode\ndf.main %&gt;% \n  filter(is.na(deaths_total)) %&gt;%  # to check for missing values\n  nrow() \n\n\n[1] 0\n\n\nCode\n# Get vaccination starting date:\ndf.main %&gt;% \n  filter(is.na(daily_vacc_doses)) %&gt;% nrow()\n\n\n[1] 14050\n\n\nCode\n# There are 14050 missing data for vaccination doses.\n\n\n# Get the minimum date for non-missing values of vaccination doses\ndf_state_vaccDatesMin &lt;- df.main %&gt;% \n  filter(!is.na(daily_vacc_doses)) %&gt;% \n  group_by(state) %&gt;% \n  reframe(min_date = min(date)) %&gt;% \n  summarise(min_date = min(min_date))\n\n\n## replace NAs, calculate daily counts and total counts\ndf.main &lt;- df.main %&gt;% \n  mutate(population_in_mil = round(population / 10e6, 2),\n         daily_vacc_doses = replace_na(daily_vacc_doses, \n                                       replace = 0)) %&gt;%\n  # get daily count:\n  group_by(state) %&gt;% \n  mutate(confirmed_daily_cases = \n           confirmed_total - lag(confirmed_total, n = 1),\n         death_daily_cases = \n             deaths_total - lag(deaths_total, n = 1)) %&gt;% \n  mutate(vaccine_doses_total = cumsum(daily_vacc_doses)) %&gt;% \n  ungroup() %&gt;% \n  select(state_id:date,\n         confirmed_total, confirmed_daily_cases,\n         deaths_total, death_daily_cases,\n         vaccine_doses_total, daily_vacc_doses,\n         everything())\n\n\n## check for negative values and replace them with zero, because some data were not reported:\ndf.main &lt;- df.main %&gt;% \n  mutate_at(.tbl = .,\n            .vars = c(\"confirmed_daily_cases\", \n                      \"death_daily_cases\", \"vaccine_doses_total\"),\n            .funs = function(.vars) {ifelse(.vars &lt; 0, 0, .vars)}) \n\n\nResult:\n\nSince I used left-join, I expected some Missing Values on the merged records.\nPerhaps I should have used inner join, however, I wanted to account for days where the states failed to record the cases, thereby catching the inconsistencies and noting them in the EDA.\nBecause we replaced missing records with 0, I suspected performing a lag for confirmed_total, deaths_total and vaccine_doses_total, would cause some negative values which means there was a drop in the report from the states.\nI replaced these negative values with 0 since you cannot quantify that you had negative number of reported cases. This doesn’t really make sense to others unless you’re being mathematical.\n\n\n\n\n\n\n\nCode\n## Get total number of infections and deaths:\n# - states per region\ndf.main %&gt;% \n  group_by(region) %&gt;% \n  reframe(states = n_distinct(state),\n          total_death = sum(deaths_total),\n          confirmed_total = sum(confirmed_total))\n\n\n# A tibble: 4 × 4\n  region        states total_death confirmed_total\n  &lt;fct&gt;          &lt;int&gt;       &lt;dbl&gt;           &lt;dbl&gt;\n1 Northeast          9    38364209      1081429125\n2 South             16    44545840      2571405091\n3 North Central     12    26293166      1424039247\n4 West              13    22062974      1428613518\n\n\nCode\n## show states on map:\nmax_date &lt;- df.main %&gt;% pull(date) %&gt;% max(.)\n\n## states to lower case:\ndf.main &lt;- df.main %&gt;% \n  mutate(state_ = str_to_lower(string = state))\n\n\ndf.main %&gt;% \n  filter(date == max_date) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = group)) +\n  geom_polygon(aes(fill = region),\n               color = \"black\") +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank())\n\n\n\n\n\n\n\n\n\nResults:\n\nHere, I wanted to get a rough feel for the total number of infections and deaths by region and I used a map to see that."
  },
  {
    "objectID": "eda.html#question-1-how-does-total-number-of-confirmed-cases-and-covid-19-related-deaths-change-over-time---on-a-regional-level---on-a-national-level---on-a-state-level",
    "href": "eda.html#question-1-how-does-total-number-of-confirmed-cases-and-covid-19-related-deaths-change-over-time---on-a-regional-level---on-a-national-level---on-a-state-level",
    "title": "EDA Process",
    "section": "",
    "text": "Here, we want to look at the total number of confirmed cases as they change over time.\n\n\nCode\n## Get relative counts:\ndf.main &lt;- df.main %&gt;% \n  mutate(confirmed_totalPerc = confirmed_total / population,\n          deaths_totalPerc = deaths_total / population)\n  \n\n ## add region groups:\ndf_regionGroup &lt;- df.main %&gt;% \n  group_by(region) %&gt;% \n  count(state) %&gt;% \n  ungroup() %&gt;% \n  arrange(region, state) %&gt;% \n  # add state count:\n  group_by(region) %&gt;% \n  mutate(states = n(),\n         id = row_number()) %&gt;% \n  ungroup() %&gt;% \n  # add group id:\n  mutate(group = case_when(id &lt;= round(states / 2, 0) ~ 1, \n                           T ~ 2)) %&gt;% \n  mutate(region_group = paste(region, \"- group\", group, sep = \" \")) %&gt;% \n  select(state, region_group)\n\n\n\n## bring groups to main table:\ndf.main &lt;- df.main %&gt;%\n  left_join(x = .,\n            y = df_regionGroup,\n            by = \"state\")\n\n## Plot:\nregion_group &lt;- df_regionGroup %&gt;% \n  distinct(region_group) %&gt;% \n  pull(region_group)\n\n#plotConfirmedCasesTotal(region.group = \"Northeast - group 1\")  \n\n## Plot for each region and group:\nregion_group\n\n\n[1] \"Northeast - group 1\"     \"Northeast - group 2\"    \n[3] \"South - group 1\"         \"South - group 2\"        \n[5] \"North Central - group 1\" \"North Central - group 2\"\n[7] \"West - group 1\"          \"West - group 2\"         \n\n\nCode\nmap(.x = region_group, .f = ~plotConfirmedCasesTotal(region.group = .x))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[[1]]\n[1] \"./explore/01_confirmed_cases_and_deaths Northeast - group 1 .png\"\n\n[[2]]\n[1] \"./explore/01_confirmed_cases_and_deaths Northeast - group 2 .png\"\n\n[[3]]\n[1] \"./explore/01_confirmed_cases_and_deaths South - group 1 .png\"\n\n[[4]]\n[1] \"./explore/01_confirmed_cases_and_deaths South - group 2 .png\"\n\n[[5]]\n[1] \"./explore/01_confirmed_cases_and_deaths North Central - group 1 .png\"\n\n[[6]]\n[1] \"./explore/01_confirmed_cases_and_deaths North Central - group 2 .png\"\n\n[[7]]\n[1] \"./explore/01_confirmed_cases_and_deaths West - group 1 .png\"\n\n[[8]]\n[1] \"./explore/01_confirmed_cases_and_deaths West - group 2 .png\"\n\n\nFeatures and Outputs:\n\nI created new columns for relative counts in percentage by dividing the infection and deaths total by the population.\nI added a region group column for each region, so I can properly categorize by each region. It felt easier for me this way.\nThen I created a plot for each region’s group to track the pandemic’s progression for each region."
  },
  {
    "objectID": "eda.html#question-2-which-us-state-had-the-highest-percentage-of-confirmed-cases-and-deaths-relative-count",
    "href": "eda.html#question-2-which-us-state-had-the-highest-percentage-of-confirmed-cases-and-deaths-relative-count",
    "title": "EDA Process",
    "section": "",
    "text": "Code\n## bar chart:\nplot &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, state, confirmed_totalPerc, deaths_totalPerc) %&gt;% \n  rename(`confirmed total %` = confirmed_totalPerc, \n         `death total %` = deaths_totalPerc) %&gt;% \n  # convert from wide to long:\n  pivot_longer(cols = c(`confirmed total %`, `death total %`),\n               names_to = \"percentage\",\n               values_to = \"values\") %&gt;% \n  group_by(state) %&gt;% \n  mutate(total_perc = sum(values)) %&gt;% \n  ungroup() %&gt;% \n  arrange(total_perc, state) %&gt;% \n  mutate(state = as.factor(state)) %&gt;% \n  mutate(state = fct_inorder(state)) %&gt;% \n  ggplot(mapping = aes(x = values,\n                       y = state,\n                       fill = region)) +\n  geom_col(color = \"black\") +\n  facet_wrap(percentage ~ .,\n             scales = \"free\") + \n  xlab(\"Percentage of State Population\") +\n  ylab(\"State\") +\n  ggtitle(\"Barplot of Confirmed Cases and Deaths for Each State\") +\n  scale_fill_viridis_d() +\n  theme_minimal()\n\ndir = \"./explore\"\nif (!dir.exists(dir))\n{\n    dir.create(dir)\n}\n\n# export plot:\nggsave(filename = \n         \"./explore/02_Barplot_of_Confirmed_Cases_and_Deaths_Per_State.png\",\n       plot = plot,\n       width = 30,\n       height = 25,\n       units = \"cm\")\n\n\n\ndf_samp &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, region_group, state, state_, confirmed_totalPerc, deaths_totalPerc) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  rename(`confirmed total %` = confirmed_totalPerc, \n         `death total %` = deaths_totalPerc) %&gt;% \n  pivot_longer(cols = c(`confirmed total %`, `death total %`),\n               names_to = \"percentage\",\n               values_to = \"values\") %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = state)) +\n  geom_polygon(aes(fill = values),\n               color = \"black\",\n               show.legend = T) +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank()) + \n  scale_fill_viridis_c(option = \"inferno\")\n\n\n## Create a map regarding relative counts:\ndf.main &lt;- df.main %&gt;% \n  rename(`confirmed total %` = confirmed_totalPerc, \n         `death total %` = deaths_totalPerc)\n\n\np2 &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, state_, state, `confirmed total %`, `death total %`) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = state)) +\n  geom_polygon(aes(fill = `confirmed total %`),\n               color = \"black\",\n               show.legend = T) +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"Percentage of Confirmed Cases for Each State Population\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank()) + \n  scale_fill_viridis_c(option = \"inferno\")\n\n\np1 &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  select(region, state_, state, `confirmed total %`, `death total %`) %&gt;% \n  # get longitude and latitude for each state:\n  left_join(x = .,\n            y = map_data(\"state\"),\n            by = c(\"state_\" = \"region\")) %&gt;% \n  ggplot(mapping = aes(x = long,\n                       y = lat,\n                       group = state)) +\n  geom_polygon(aes(fill = `death total %`),\n               color = \"black\",\n               show.legend = T) +\n  xlab(\"\") +\n  ylab(\"\") +\n  ggtitle(\"Percentage of Death Cases for Each State Population\") +\n  theme_bw() +\n  theme(axis.ticks = element_blank(),\n        axis.text = element_blank()) + \n  scale_fill_gradient(low = \"white\", high = \"black\")\n\nplot &lt;- plot_grid(p1, p2, nrow = 2)\n\n# export plot:\nggsave(filename = \n         \"./explore/02_Map_of_Confirmed_Cases_and_Deaths_Per_State.png\",\n       plot = plot,\n       width = 30,\n       height = 25,\n       units = \"cm\")\n\n\nResults:\n\nBar charts are created here for relative counts in percentage of death cases and infection for each state population.\nMaps are also created to see the percentage across all states using a continuous scale for the color.\nPlots are then saved to ./explore directory."
  },
  {
    "objectID": "eda.html#question-3-daily-pandemic-dynamics-how-do-daily-confirmed-cases-and-deaths-change-over-time",
    "href": "eda.html#question-3-daily-pandemic-dynamics-how-do-daily-confirmed-cases-and-deaths-change-over-time",
    "title": "EDA Process",
    "section": "",
    "text": "Here, we want to look at how daily confirmed cases and deaths change over time. Essentially, we’ll be performed a time series. The plot in the code block below will have jumps that we will smoothen out in the second code block. The first is kind of to see for ourselves the jags, which will help us realize the need for a moving average!\n\n\nCode\ndf.main %&gt;% \n  group_by(state, date) %&gt;% \n  arrange(state, date) %&gt;% \n  mutate_at(.tbl = .,\n            .vars = c(\"confirmed_daily_cases\", \"death_daily_cases\"),\n            .funs = function(x){ifelse(is.na(x), 0, x)}) %&gt;% \n  pivot_longer(data = .,\n               cols = c(\"confirmed_daily_cases\", \"death_daily_cases\"),\n               names_to = \"daily_cases\",\n               values_to = \"values\") %&gt;% \n  ggplot(mapping = aes(x = date,\n                       y = values,\n                       color = daily_cases)) +\n  geom_line(show.legend = F) + \n  facet_wrap(region ~ ., scales = \"free\")\n\n\n\n\n\n\n\n\n\nResults:\n\nHere, you will see that our first time series have jumps since missing values and negative were replaced with zeros earlier in the data cleaning because there were inconsistencies in the reporting of data by states.\nInstead, we use a moving average to smooth out these jumps.\n\n\n\nCode\nlibrary(zoo)\n\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  group_by(state) %&gt;% \n  mutate( across( .cols = c(confirmed_daily_cases, death_daily_cases),\n                  ~ rollapply(data = ., width = 7, FUN = mean, fill = NA, \n                              align = \"right\", na.rm = TRUE),\n      .names = \"{.col} 7d Avg\")) %&gt;% \n  ungroup()\n\n\n\n\n\n\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  group_by(state) %&gt;% \n  mutate( across( .cols = c(confirmed_daily_cases, death_daily_cases),\n                  ~ rollapply(data = ., width = 7, FUN = mean, fill = NA, \n                              align = \"right\", na.rm = TRUE),\n      .names = \"{.col} 7d Avg\")) %&gt;% \n  ungroup()\n\n# data validation \ndf.main %&gt;% \n  filter(is.na(`confirmed_daily_cases 7d Avg`)) %&gt;% \n  select(`confirmed_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\ndf.main %&gt;% \n  filter(is.na(`death_daily_cases 7d Avg`)) %&gt;% \n  select(`death_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\n# Data validation here: check for missing values\ndf.main %&gt;% \n  filter(is.na(`confirmed_daily_cases 7d Avg`)) %&gt;% \n  select(`confirmed_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\ndf.main %&gt;% \n  filter(is.na(`death_daily_cases 7d Avg`)) %&gt;% \n  select(`death_daily_cases 7d Avg`) %&gt;% \n  nrow()\n\n\n[1] 300\n\n\nCode\n# Plot for each region:\ndf.main %&gt;% \n  pivot_longer(data = .,\n               cols =\n                 c(`confirmed_daily_cases 7d Avg`, `death_daily_cases 7d Avg`),\n               names_to = \"daily_cases\",\n               values_to = \"values\") %&gt;% \n  ggplot(mapping = aes(x = date,\n                       y = values,\n                       color = daily_cases)) +\n  geom_line(show.legend = F, alpha = 0.7) + \n  scale_fill_viridis_d() +\n  facet_wrap(region ~ ., scales = \"free\")\n\n\n\n\n\n\n\n\n\nCode\n# Plot:\nmap(.x = region_group, \n    .f = ~ plot7DayAverage(region.group = .x))\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\nFeatures:\n\nWe added a 7 day moving average columns for the confirmed_daily_cases and death_daily_cases to the df.main\nThen we did data validation to check for missing values in the moving averages. We should expect No missing values in the moving average, because the essence of the moving average is to smooth out the jumps in the time series.\nThe plot returned from the code block should show the smoothed time series for the pandemic dynamics."
  },
  {
    "objectID": "eda.html#question-4-is-there-a-connection-between-state-wealth-state-population-confirmed-cases-and-deaths",
    "href": "eda.html#question-4-is-there-a-connection-between-state-wealth-state-population-confirmed-cases-and-deaths",
    "title": "EDA Process",
    "section": "",
    "text": "I’ll reframe a bit: Do state wealth and/or state population have an effect on total percentage of confirmed cases and deaths?\nThough we cannot say it DOES, but plotting the scatterplot will show if there is some kind of relationship that we can notice ourselves.\n\n\nCode\nplot &lt;- df.main %&gt;% \n  filter(date == max_date) %&gt;% \n  ggplot(aes(x = `confirmed total %`,\n             y = `death total %`,\n             size = population_in_mil,\n             color = gdp_per_capita)) +\n  geom_point(alpha = 0.75,\n             show.legend = T) +\n  facet_wrap(. ~ region, scales = \"free\") +\n  scale_color_gradient(low=\"brown1\", high=\"green\") +\n  scale_size_area(max_size = 30) +\n  theme_minimal() +\n  xlab(\"Total Confirmed Cases %\") +\n  ylab(\"Total Deaths %\") +\n  ggtitle(\"Total Confirmed Cases and Total Deaths % VS GDP and population\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\nfilename &lt;- file.path(paste0(\"./explore/04_total_confirmed_deaths_perc_gdp_pop_and_scatter.png\"))\n\n# Save plot\nggsave(filename = filename,\n       plot = plot,\n       width = 35, height = 25, units = \"cm\",\n       dpi = 1200)\n\n\nFeatures:\n\nWe plot scatter-plots to try to visualize the relationship.\nThese plots are saved in the ./explore directory as well."
  },
  {
    "objectID": "eda.html#question-5-does-vaccination-help-fighting-the-covid-19-pandemic-i.e-does-vaccination-help-decrease-covid-19-confirmed-cases-and-death-toll",
    "href": "eda.html#question-5-does-vaccination-help-fighting-the-covid-19-pandemic-i.e-does-vaccination-help-decrease-covid-19-confirmed-cases-and-death-toll",
    "title": "EDA Process",
    "section": "",
    "text": "Code\nmap(.x = region_group,\n    .f = ~ plot_vaccineDosesTotal_7DayAVg(region.group = .x))\n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\nFeatures:\n\nHere, we plot the moving averages of the cummulative sum of vaccine doses already calculated from before to see the trend of the does, confirmed cases and death toll."
  },
  {
    "objectID": "eda.html#question-6-can-you-see-the-effect-of-government-response-against-covid-19-pandemic",
    "href": "eda.html#question-6-can-you-see-the-effect-of-government-response-against-covid-19-pandemic",
    "title": "EDA Process",
    "section": "",
    "text": "Here we show on map how number of COVID-case have changed over time (monthly).\n\n\nCode\n# add date id and snapshot flag\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  # date id per state:\n  group_by(state) %&gt;% \n  mutate(date_id = row_number()) %&gt;% \n  ungroup() %&gt;% \n  # add date snapshot flag for every 30th day:\n  mutate(date_snapshot_flag = case_when(date_id == 1 ~ TRUE,\n                                       date_id == max_date ~ TRUE,\n                                       date_id %% 30 == 0 ~ TRUE,\n                                       TRUE ~ FALSE))\n\n# plot the maps:\nvariables &lt;- c(\"confirmed_total\", \"deaths_total\", \"vaccine_doses_total\")\n\nplots &lt;- map(variables, ~ plotCovid19Map_overTime(df.main, .x))\n\n\nFeatures:\n\nA new columns for the date flag for every 30th day (month) is created.\nStacked area charts of covid 19 indicators in a log-scale time series are shown, as well as the government response metrics."
  },
  {
    "objectID": "eda.html#question-7-how-high-was-the-response-rate-of-each-state-towards-pandemic",
    "href": "eda.html#question-7-how-high-was-the-response-rate-of-each-state-towards-pandemic",
    "title": "EDA Process",
    "section": "",
    "text": "We sort by state, date then the stringency index, grouping by state and seeing the stacked area charts of the stringency index for display.\n\n\nCode\nwStringencyIndex &lt;- df.main %&gt;% \n  arrange(state, date, stringency_index_for_display) %&gt;% \n  # date id per state:\n  group_by(state) %&gt;% \n  mutate(date_id = row_number()) %&gt;% \n  ungroup() %&gt;% \n  # add date snapshot flag for every 30th day:\n  mutate(date_snapshot_flag = case_when(date_id == 1 ~ TRUE,\n                                        date_id == max_date ~ TRUE,\n                                        date_id %% 30 == 0 ~ TRUE,\n                                        TRUE ~ FALSE))\n\nplots &lt;- map(\"stringency_index_for_display\",\n             ~ plotCovid19Map_overTime(df.main, .x))"
  },
  {
    "objectID": "eda.html#question-7-how-each-state-is-doing-on-a-state-level-how-selected-states-are-coping-with-the-pandemic-over-time",
    "href": "eda.html#question-7-how-each-state-is-doing-on-a-state-level-how-selected-states-are-coping-with-the-pandemic-over-time",
    "title": "EDA Process",
    "section": "",
    "text": "Here we look at the vaccine smoothed daily counts by creating first the 7 day moving average column and plotting for some states here: California, Texas, New York are used as examples.\n\n\nCode\n## vaccine smoothed daily counts:\ndf.main &lt;- df.main %&gt;% \n  arrange(state, date) %&gt;% \n  group_by(state) %&gt;% \n  mutate(across( .cols = daily_vacc_doses,\n                  ~ rollapply(data = ., width = 7, FUN = mean, fill = NA, \n                              align = \"right\", na.rm = TRUE),\n                 .names = \"{.col} 7d Avg\")) %&gt;% \n  ungroup()\n\n\n\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"California\")\n\n\n\n\n\n\n\n\n\nCode\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"New York\")\n\n\n\n\n\n\n\n\n\nCode\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"Texas\")\n\n\n\n\n\n\n\n\n\nCode\nplotCovid19Indicators_stateLevel(data = df.main, state_selection = \"Nebraska\")"
  }
]